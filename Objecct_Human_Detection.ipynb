{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gn8LUgqYI3l"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tri0Y9ECbJlY",
        "outputId": "a2467db1-a3c0-4368-f931-7f3fa86e6e08"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s36gkHM1bGv_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FatGnnlgUcsA",
        "outputId": "0cf61281-7a3e-4582-dfe3-6c59674ed5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.48)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWxgExVxB9Zo"
      },
      "source": [
        "**SPECIES IDENTIFICATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsJk2zFtCMvp"
      },
      "source": [
        "This code counts the number of persons or objects detected in each video frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hh8T9G-sXh-f",
        "outputId": "72c2e95e-7abe-4d37-b679-cc26b213148e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 158.5ms\n",
            "video 1/1 (frame 2/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 135.0ms\n",
            "video 1/1 (frame 3/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 333.2ms\n",
            "video 1/1 (frame 4/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 144.3ms\n",
            "video 1/1 (frame 5/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 138.3ms\n",
            "video 1/1 (frame 6/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 134.7ms\n",
            "video 1/1 (frame 7/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 302.5ms\n",
            "video 1/1 (frame 8/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 144.3ms\n",
            "video 1/1 (frame 9/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 131.7ms\n",
            "video 1/1 (frame 10/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 176.7ms\n",
            "video 1/1 (frame 11/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 146.6ms\n",
            "video 1/1 (frame 12/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 146.6ms\n",
            "video 1/1 (frame 13/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 135.9ms\n",
            "video 1/1 (frame 14/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 140.3ms\n",
            "video 1/1 (frame 15/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 141.9ms\n",
            "video 1/1 (frame 16/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 141.9ms\n",
            "video 1/1 (frame 17/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 155.1ms\n",
            "video 1/1 (frame 18/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 154.7ms\n",
            "video 1/1 (frame 19/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 133.8ms\n",
            "video 1/1 (frame 20/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 130.5ms\n",
            "video 1/1 (frame 21/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 133.8ms\n",
            "video 1/1 (frame 22/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 147.6ms\n",
            "video 1/1 (frame 23/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 132.5ms\n",
            "video 1/1 (frame 24/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 139.4ms\n",
            "video 1/1 (frame 25/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 154.6ms\n",
            "video 1/1 (frame 26/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 132.1ms\n",
            "video 1/1 (frame 27/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 133.5ms\n",
            "video 1/1 (frame 28/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 131.0ms\n",
            "video 1/1 (frame 29/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 146.1ms\n",
            "video 1/1 (frame 30/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 134.0ms\n",
            "video 1/1 (frame 31/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 128.2ms\n",
            "video 1/1 (frame 32/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 135.3ms\n",
            "video 1/1 (frame 33/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 139.5ms\n",
            "video 1/1 (frame 34/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 154.4ms\n",
            "video 1/1 (frame 35/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 142.1ms\n",
            "video 1/1 (frame 36/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 138.3ms\n",
            "video 1/1 (frame 37/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 136.4ms\n",
            "video 1/1 (frame 38/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 143.8ms\n",
            "video 1/1 (frame 39/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 137.4ms\n",
            "video 1/1 (frame 40/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 130.4ms\n",
            "video 1/1 (frame 41/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 140.3ms\n",
            "video 1/1 (frame 42/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 5 persons, 152.2ms\n",
            "video 1/1 (frame 43/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 5 persons, 147.8ms\n",
            "video 1/1 (frame 44/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 5 persons, 129.1ms\n",
            "video 1/1 (frame 45/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 141.4ms\n",
            "video 1/1 (frame 46/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 152.7ms\n",
            "video 1/1 (frame 47/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 131.9ms\n",
            "video 1/1 (frame 48/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 153.3ms\n",
            "video 1/1 (frame 49/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 168.6ms\n",
            "video 1/1 (frame 50/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 208.9ms\n",
            "video 1/1 (frame 51/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 203.1ms\n",
            "video 1/1 (frame 52/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 198.3ms\n",
            "video 1/1 (frame 53/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 223.3ms\n",
            "video 1/1 (frame 54/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 208.0ms\n",
            "video 1/1 (frame 55/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 211.3ms\n",
            "video 1/1 (frame 56/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 213.0ms\n",
            "video 1/1 (frame 57/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 209.8ms\n",
            "video 1/1 (frame 58/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 199.9ms\n",
            "video 1/1 (frame 59/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 199.6ms\n",
            "video 1/1 (frame 60/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 225.2ms\n",
            "video 1/1 (frame 61/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 207.4ms\n",
            "video 1/1 (frame 62/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 229.3ms\n",
            "video 1/1 (frame 63/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 236.1ms\n",
            "video 1/1 (frame 64/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 200.7ms\n",
            "video 1/1 (frame 65/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 206.7ms\n",
            "video 1/1 (frame 66/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 164.2ms\n",
            "video 1/1 (frame 67/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 130.0ms\n",
            "video 1/1 (frame 68/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 142.1ms\n",
            "video 1/1 (frame 69/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 136.6ms\n",
            "video 1/1 (frame 70/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 145.9ms\n",
            "video 1/1 (frame 71/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 142.0ms\n",
            "video 1/1 (frame 72/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 148.4ms\n",
            "video 1/1 (frame 73/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 144.5ms\n",
            "video 1/1 (frame 74/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 134.3ms\n",
            "video 1/1 (frame 75/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 148.5ms\n",
            "video 1/1 (frame 76/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 131.1ms\n",
            "video 1/1 (frame 77/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 130.7ms\n",
            "video 1/1 (frame 78/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 141.9ms\n",
            "video 1/1 (frame 79/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 153.1ms\n",
            "video 1/1 (frame 80/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 135.6ms\n",
            "video 1/1 (frame 81/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 147.6ms\n",
            "video 1/1 (frame 82/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 143.0ms\n",
            "video 1/1 (frame 83/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 153.9ms\n",
            "video 1/1 (frame 84/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 243.5ms\n",
            "video 1/1 (frame 85/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 197.3ms\n",
            "video 1/1 (frame 86/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 133.5ms\n",
            "video 1/1 (frame 87/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 128.5ms\n",
            "video 1/1 (frame 88/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 132.9ms\n",
            "video 1/1 (frame 89/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 139.6ms\n",
            "video 1/1 (frame 90/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 137.4ms\n",
            "video 1/1 (frame 91/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 142.7ms\n",
            "video 1/1 (frame 92/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 140.5ms\n",
            "video 1/1 (frame 93/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 134.6ms\n",
            "video 1/1 (frame 94/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 133.4ms\n",
            "video 1/1 (frame 95/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 134.2ms\n",
            "video 1/1 (frame 96/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 136.9ms\n",
            "video 1/1 (frame 97/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 133.7ms\n",
            "video 1/1 (frame 98/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 152.9ms\n",
            "video 1/1 (frame 99/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.0ms\n",
            "video 1/1 (frame 100/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 4 persons, 131.9ms\n",
            "video 1/1 (frame 101/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 4 persons, 134.3ms\n",
            "video 1/1 (frame 102/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.2ms\n",
            "video 1/1 (frame 103/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.0ms\n",
            "video 1/1 (frame 104/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 142.5ms\n",
            "video 1/1 (frame 105/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 152.2ms\n",
            "video 1/1 (frame 106/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 129.5ms\n",
            "video 1/1 (frame 107/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 143.8ms\n",
            "video 1/1 (frame 108/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 135.6ms\n",
            "video 1/1 (frame 109/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 130.3ms\n",
            "video 1/1 (frame 110/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 128.8ms\n",
            "video 1/1 (frame 111/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 154.6ms\n",
            "video 1/1 (frame 112/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 137.5ms\n",
            "video 1/1 (frame 113/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 149.5ms\n",
            "video 1/1 (frame 114/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 144.4ms\n",
            "video 1/1 (frame 115/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 133.5ms\n",
            "video 1/1 (frame 116/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 130.9ms\n",
            "video 1/1 (frame 117/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 143.3ms\n",
            "video 1/1 (frame 118/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 157.4ms\n",
            "video 1/1 (frame 119/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 146.5ms\n",
            "video 1/1 (frame 120/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 139.6ms\n",
            "video 1/1 (frame 121/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 139.6ms\n",
            "video 1/1 (frame 122/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 131.8ms\n",
            "video 1/1 (frame 123/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 134.7ms\n",
            "video 1/1 (frame 124/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 226.4ms\n",
            "video 1/1 (frame 125/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 163.0ms\n",
            "video 1/1 (frame 126/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 137.3ms\n",
            "video 1/1 (frame 127/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 144.1ms\n",
            "video 1/1 (frame 128/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 200.7ms\n",
            "video 1/1 (frame 129/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 220.1ms\n",
            "video 1/1 (frame 130/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 219.0ms\n",
            "video 1/1 (frame 131/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 213.7ms\n",
            "video 1/1 (frame 132/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 194.3ms\n",
            "video 1/1 (frame 133/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 202.1ms\n",
            "video 1/1 (frame 134/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 220.3ms\n",
            "video 1/1 (frame 135/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 230.3ms\n",
            "video 1/1 (frame 136/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 219.9ms\n",
            "video 1/1 (frame 137/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 218.8ms\n",
            "video 1/1 (frame 138/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 213.9ms\n",
            "video 1/1 (frame 139/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 227.9ms\n",
            "video 1/1 (frame 140/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 198.8ms\n",
            "video 1/1 (frame 141/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 215.1ms\n",
            "video 1/1 (frame 142/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 204.2ms\n",
            "video 1/1 (frame 143/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 360.4ms\n",
            "video 1/1 (frame 144/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 191.5ms\n",
            "video 1/1 (frame 145/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 137.1ms\n",
            "video 1/1 (frame 146/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 130.1ms\n",
            "video 1/1 (frame 147/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 142.1ms\n",
            "video 1/1 (frame 148/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 130.7ms\n",
            "video 1/1 (frame 149/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 144.4ms\n",
            "video 1/1 (frame 150/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 140.2ms\n",
            "video 1/1 (frame 151/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 139.7ms\n",
            "video 1/1 (frame 152/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 128.9ms\n",
            "video 1/1 (frame 153/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 145.1ms\n",
            "video 1/1 (frame 154/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 135.2ms\n",
            "video 1/1 (frame 155/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 150.3ms\n",
            "video 1/1 (frame 156/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 146.5ms\n",
            "video 1/1 (frame 157/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 142.6ms\n",
            "video 1/1 (frame 158/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 139.3ms\n",
            "video 1/1 (frame 159/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 140.4ms\n",
            "video 1/1 (frame 160/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 247.0ms\n",
            "video 1/1 (frame 161/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 156.0ms\n",
            "video 1/1 (frame 162/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 138.6ms\n",
            "video 1/1 (frame 163/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 134.0ms\n",
            "video 1/1 (frame 164/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 135.0ms\n",
            "video 1/1 (frame 165/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 134.7ms\n",
            "video 1/1 (frame 166/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.7ms\n",
            "video 1/1 (frame 167/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 148.1ms\n",
            "video 1/1 (frame 168/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 139.0ms\n",
            "video 1/1 (frame 169/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 216.4ms\n",
            "video 1/1 (frame 170/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 176.5ms\n",
            "video 1/1 (frame 171/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 135.2ms\n",
            "video 1/1 (frame 172/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 139.5ms\n",
            "video 1/1 (frame 173/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 141.3ms\n",
            "video 1/1 (frame 174/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 146.6ms\n",
            "video 1/1 (frame 175/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 128.6ms\n",
            "video 1/1 (frame 176/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 133.0ms\n",
            "video 1/1 (frame 177/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 138.6ms\n",
            "video 1/1 (frame 178/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 143.8ms\n",
            "video 1/1 (frame 179/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 146.4ms\n",
            "video 1/1 (frame 180/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.9ms\n",
            "video 1/1 (frame 181/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 147.8ms\n",
            "video 1/1 (frame 182/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 136.5ms\n",
            "video 1/1 (frame 183/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 143.5ms\n",
            "video 1/1 (frame 184/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 135.0ms\n",
            "video 1/1 (frame 185/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 141.4ms\n",
            "video 1/1 (frame 186/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 154.5ms\n",
            "video 1/1 (frame 187/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 150.2ms\n",
            "video 1/1 (frame 188/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.8ms\n",
            "video 1/1 (frame 189/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 140.8ms\n",
            "video 1/1 (frame 190/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 140.0ms\n",
            "video 1/1 (frame 191/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 143.1ms\n",
            "video 1/1 (frame 192/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 143.5ms\n",
            "video 1/1 (frame 193/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 141.7ms\n",
            "video 1/1 (frame 194/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 137.1ms\n",
            "video 1/1 (frame 195/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 146.2ms\n",
            "video 1/1 (frame 196/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 129.8ms\n",
            "video 1/1 (frame 197/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 137.4ms\n",
            "video 1/1 (frame 198/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 131.5ms\n",
            "video 1/1 (frame 199/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 153.4ms\n",
            "video 1/1 (frame 200/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 130.4ms\n",
            "video 1/1 (frame 201/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 136.1ms\n",
            "video 1/1 (frame 202/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 157.2ms\n",
            "video 1/1 (frame 203/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 144.4ms\n",
            "video 1/1 (frame 204/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 136.5ms\n",
            "video 1/1 (frame 205/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 150.0ms\n",
            "video 1/1 (frame 206/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 209.4ms\n",
            "video 1/1 (frame 207/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 227.0ms\n",
            "video 1/1 (frame 208/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 200.1ms\n",
            "video 1/1 (frame 209/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 210.9ms\n",
            "video 1/1 (frame 210/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 200.2ms\n",
            "video 1/1 (frame 211/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 213.4ms\n",
            "video 1/1 (frame 212/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 208.8ms\n",
            "video 1/1 (frame 213/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 205.1ms\n",
            "video 1/1 (frame 214/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 202.0ms\n",
            "video 1/1 (frame 215/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 206.7ms\n",
            "video 1/1 (frame 216/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 203.9ms\n",
            "video 1/1 (frame 217/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 212.1ms\n",
            "video 1/1 (frame 218/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 202.9ms\n",
            "video 1/1 (frame 219/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 224.6ms\n",
            "video 1/1 (frame 220/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 211.1ms\n",
            "video 1/1 (frame 221/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 227.6ms\n",
            "video 1/1 (frame 222/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 150.2ms\n",
            "video 1/1 (frame 223/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 138.4ms\n",
            "video 1/1 (frame 224/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.6ms\n",
            "video 1/1 (frame 225/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 149.5ms\n",
            "video 1/1 (frame 226/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 133.6ms\n",
            "video 1/1 (frame 227/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 142.7ms\n",
            "video 1/1 (frame 228/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 141.0ms\n",
            "video 1/1 (frame 229/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 148.6ms\n",
            "video 1/1 (frame 230/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.1ms\n",
            "video 1/1 (frame 231/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 134.8ms\n",
            "video 1/1 (frame 232/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 153.4ms\n",
            "video 1/1 (frame 233/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 145.1ms\n",
            "video 1/1 (frame 234/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 139.5ms\n",
            "video 1/1 (frame 235/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 134.8ms\n",
            "video 1/1 (frame 236/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 140.3ms\n",
            "video 1/1 (frame 237/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 145.1ms\n",
            "video 1/1 (frame 238/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 141.0ms\n",
            "video 1/1 (frame 239/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 139.6ms\n",
            "video 1/1 (frame 240/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 144.5ms\n",
            "video 1/1 (frame 241/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 131.5ms\n",
            "video 1/1 (frame 242/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 142.3ms\n",
            "video 1/1 (frame 243/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 143.1ms\n",
            "video 1/1 (frame 244/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 146.1ms\n",
            "video 1/1 (frame 245/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 132.9ms\n",
            "video 1/1 (frame 246/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 146.1ms\n",
            "video 1/1 (frame 247/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 130.4ms\n",
            "video 1/1 (frame 248/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 141.0ms\n",
            "video 1/1 (frame 249/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 136.2ms\n",
            "video 1/1 (frame 250/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 162.0ms\n",
            "video 1/1 (frame 251/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 136.3ms\n",
            "video 1/1 (frame 252/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 147.4ms\n",
            "video 1/1 (frame 253/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 132.9ms\n",
            "video 1/1 (frame 254/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.1ms\n",
            "video 1/1 (frame 255/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 138.2ms\n",
            "video 1/1 (frame 256/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 153.7ms\n",
            "video 1/1 (frame 257/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 152.2ms\n",
            "video 1/1 (frame 258/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 141.2ms\n",
            "video 1/1 (frame 259/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 133.6ms\n",
            "video 1/1 (frame 260/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 137.0ms\n",
            "video 1/1 (frame 261/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 133.7ms\n",
            "video 1/1 (frame 262/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 154.6ms\n",
            "video 1/1 (frame 263/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 131.1ms\n",
            "video 1/1 (frame 264/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 140.3ms\n",
            "video 1/1 (frame 265/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 132.8ms\n",
            "video 1/1 (frame 266/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 136.3ms\n",
            "video 1/1 (frame 267/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 130.4ms\n",
            "video 1/1 (frame 268/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.4ms\n",
            "video 1/1 (frame 269/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 144.3ms\n",
            "video 1/1 (frame 270/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 152.2ms\n",
            "video 1/1 (frame 271/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 134.7ms\n",
            "video 1/1 (frame 272/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 141.4ms\n",
            "video 1/1 (frame 273/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 129.9ms\n",
            "video 1/1 (frame 274/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 140.6ms\n",
            "video 1/1 (frame 275/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 150.8ms\n",
            "video 1/1 (frame 276/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 145.2ms\n",
            "video 1/1 (frame 277/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 132.7ms\n",
            "video 1/1 (frame 278/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 144.8ms\n",
            "video 1/1 (frame 279/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 136.3ms\n",
            "video 1/1 (frame 280/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 4 persons, 140.1ms\n",
            "video 1/1 (frame 281/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 4 persons, 138.5ms\n",
            "video 1/1 (frame 282/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 4 persons, 150.7ms\n",
            "video 1/1 (frame 283/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 1 train, 133.6ms\n",
            "video 1/1 (frame 284/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 179.8ms\n",
            "video 1/1 (frame 285/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 1 train, 202.4ms\n",
            "video 1/1 (frame 286/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 1 train, 204.8ms\n",
            "video 1/1 (frame 287/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 221.1ms\n",
            "video 1/1 (frame 288/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 209.4ms\n",
            "video 1/1 (frame 289/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 189.0ms\n",
            "video 1/1 (frame 290/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 216.7ms\n",
            "video 1/1 (frame 291/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 227.6ms\n",
            "video 1/1 (frame 292/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 204.8ms\n",
            "video 1/1 (frame 293/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 199.0ms\n",
            "video 1/1 (frame 294/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 210.7ms\n",
            "video 1/1 (frame 295/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 196.6ms\n",
            "video 1/1 (frame 296/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 218.8ms\n",
            "video 1/1 (frame 297/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 209.4ms\n",
            "video 1/1 (frame 298/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 208.4ms\n",
            "video 1/1 (frame 299/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 210.8ms\n",
            "video 1/1 (frame 300/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 239.4ms\n",
            "video 1/1 (frame 301/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 154.2ms\n",
            "video 1/1 (frame 302/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 136.1ms\n",
            "video 1/1 (frame 303/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 136.1ms\n",
            "video 1/1 (frame 304/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.4ms\n",
            "video 1/1 (frame 305/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.8ms\n",
            "video 1/1 (frame 306/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 158.0ms\n",
            "video 1/1 (frame 307/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 cow, 139.8ms\n",
            "video 1/1 (frame 308/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 cow, 135.1ms\n",
            "video 1/1 (frame 309/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 bird, 129.0ms\n",
            "video 1/1 (frame 310/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 bird, 144.6ms\n",
            "video 1/1 (frame 311/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 129.4ms\n",
            "video 1/1 (frame 312/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 142.7ms\n",
            "video 1/1 (frame 313/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 152.8ms\n",
            "video 1/1 (frame 314/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 138.5ms\n",
            "video 1/1 (frame 315/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 127.9ms\n",
            "video 1/1 (frame 316/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 143.3ms\n",
            "video 1/1 (frame 317/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 132.7ms\n",
            "video 1/1 (frame 318/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 146.5ms\n",
            "video 1/1 (frame 319/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 156.2ms\n",
            "video 1/1 (frame 320/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 147.9ms\n",
            "video 1/1 (frame 321/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 140.1ms\n",
            "video 1/1 (frame 322/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 143.0ms\n",
            "video 1/1 (frame 323/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 134.7ms\n",
            "video 1/1 (frame 324/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 174.1ms\n",
            "video 1/1 (frame 325/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 153.5ms\n",
            "video 1/1 (frame 326/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 145.1ms\n",
            "video 1/1 (frame 327/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 138.2ms\n",
            "video 1/1 (frame 328/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 3 persons, 148.2ms\n",
            "video 1/1 (frame 329/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 2 trains, 134.7ms\n",
            "video 1/1 (frame 330/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 2 trains, 137.7ms\n",
            "video 1/1 (frame 331/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 2 trains, 138.6ms\n",
            "video 1/1 (frame 332/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 2 trains, 140.3ms\n",
            "video 1/1 (frame 333/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 2 trains, 131.3ms\n",
            "video 1/1 (frame 334/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 138.3ms\n",
            "video 1/1 (frame 335/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 140.2ms\n",
            "video 1/1 (frame 336/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 146.6ms\n",
            "video 1/1 (frame 337/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 143.0ms\n",
            "video 1/1 (frame 338/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 2 persons, 1 train, 148.1ms\n",
            "video 1/1 (frame 339/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 129.8ms\n",
            "video 1/1 (frame 340/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 138.0ms\n",
            "video 1/1 (frame 341/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 131.8ms\n",
            "video 1/1 (frame 342/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 person, 1 train, 143.2ms\n",
            "video 1/1 (frame 343/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 139.5ms\n",
            "video 1/1 (frame 344/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 150.4ms\n",
            "video 1/1 (frame 345/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 128.4ms\n",
            "video 1/1 (frame 346/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 138.4ms\n",
            "video 1/1 (frame 347/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 132.8ms\n",
            "video 1/1 (frame 348/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 140.4ms\n",
            "video 1/1 (frame 349/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 135.1ms\n",
            "video 1/1 (frame 350/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 1 train, 138.8ms\n",
            "video 1/1 (frame 351/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 132.7ms\n",
            "video 1/1 (frame 352/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 135.1ms\n",
            "video 1/1 (frame 353/1427) /content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4: 384x640 (no detections), 134.4ms\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a0f553ec667c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict with the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# predict on an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencapsulated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mResults\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;31m# Pass the last request to the generator and get its response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# We let the exceptions raised above by the generator's `.throw` or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m             )\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                     \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.pt')  # load an official model\n",
        "#model = YOLO('path/to/best.pt')  # load a custom model\n",
        "\n",
        "# Predict with the model\n",
        "results = model('/content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4', stream = True)  # predict on an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx2CTwuYc7IZ",
        "outputId": "02b36d12-808a-4610-aee0-054d32dbf523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "90Tw_QL5GMp2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"/content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the frame width and height\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Get the frame per second (fps)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_path = \"/content/drive/MyDrive/Computer Vision/startic_annotated.mp4\"\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Convert the frame to BGR (OpenCV uses BGR)\n",
        "        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "        # Display the annotated frame\n",
        "        cv2_imshow(annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaWIR07AdCDu",
        "outputId": "faa9f82b-5849-4178-fb35-dd86cb91e62b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 76.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sdfXMFYGt-dM",
        "outputId": "21ee479a-6f65-4899-8a6f-9dbb152999f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 1 person, 379.4ms\n",
            "Speed: 9.2ms preprocess, 379.4ms inference, 2969.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 178.4ms\n",
            "Speed: 7.3ms preprocess, 178.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.6ms\n",
            "Speed: 3.6ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.2ms\n",
            "Speed: 4.3ms preprocess, 150.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.0ms\n",
            "Speed: 7.0ms preprocess, 152.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.3ms\n",
            "Speed: 5.4ms preprocess, 151.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.6ms\n",
            "Speed: 5.6ms preprocess, 145.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 141.5ms\n",
            "Speed: 4.7ms preprocess, 141.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.7ms\n",
            "Speed: 3.0ms preprocess, 154.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 171.1ms\n",
            "Speed: 3.4ms preprocess, 171.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.4ms\n",
            "Speed: 4.2ms preprocess, 152.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.2ms\n",
            "Speed: 4.7ms preprocess, 152.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.1ms\n",
            "Speed: 3.5ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.6ms\n",
            "Speed: 3.8ms preprocess, 150.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 163.1ms\n",
            "Speed: 3.7ms preprocess, 163.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.3ms\n",
            "Speed: 4.3ms preprocess, 156.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.1ms\n",
            "Speed: 3.7ms preprocess, 149.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.4ms\n",
            "Speed: 4.3ms preprocess, 149.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.0ms\n",
            "Speed: 3.5ms preprocess, 146.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 161.1ms\n",
            "Speed: 3.7ms preprocess, 161.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 155.7ms\n",
            "Speed: 3.9ms preprocess, 155.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.8ms\n",
            "Speed: 4.0ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.0ms\n",
            "Speed: 4.5ms preprocess, 146.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 152.5ms\n",
            "Speed: 4.1ms preprocess, 152.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.4ms\n",
            "Speed: 5.4ms preprocess, 151.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 157.5ms\n",
            "Speed: 4.6ms preprocess, 157.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.8ms\n",
            "Speed: 3.6ms preprocess, 149.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 151.3ms\n",
            "Speed: 4.4ms preprocess, 151.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.7ms\n",
            "Speed: 3.6ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.3ms\n",
            "Speed: 4.7ms preprocess, 153.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 157.2ms\n",
            "Speed: 3.8ms preprocess, 157.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.7ms\n",
            "Speed: 3.8ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.0ms\n",
            "Speed: 4.9ms preprocess, 150.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-41e0d3b1938e>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Wait for the detection thread to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mdetection_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Release the video capture and writer objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 384x640 2 persons, 252.3ms\n",
            "Speed: 4.1ms preprocess, 252.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.1ms\n",
            "Speed: 3.6ms preprocess, 146.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.4ms\n",
            "Speed: 3.6ms preprocess, 154.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 141.0ms\n",
            "Speed: 3.5ms preprocess, 141.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.7ms\n",
            "Speed: 4.7ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import threading\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Function for running YOLO detection in the background\n",
        "def detect_objects():\n",
        "    global model, cap, out\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "        if success:\n",
        "            results = model(frame)\n",
        "            annotated_frame = results[0].plot()\n",
        "            annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)\n",
        "            out.write(annotated_frame)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"/content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the frame width, height, and frame rate\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_path = \"/content/drive/MyDrive/Computer Vision/startic_annotated.mp4\"\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Start the thread for running YOLO detection in the background\n",
        "detection_thread = threading.Thread(target=detect_objects)\n",
        "detection_thread.start()\n",
        "\n",
        "# Wait for the detection thread to finish\n",
        "detection_thread.join()\n",
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlwQChE-8r_A"
      },
      "source": [
        "# MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IznqLD_n8yHE",
        "outputId": "83b7a0fb-0938-438c-9000-5b6ee50d65dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.48 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=VisDrone.yaml, epochs=100, time=None, patience=100, batch=10, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=exp3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.5, val=True, split=val, save_json=False, save_hybrid=False, conf=0.45, iou=0.45, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/exp3\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/exp3', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1I9_eaK3PIyivJvWadTz1JG5Vk0YGYwEz/dataset/VisDrone2019-DET-train/labels... 1075 images, 24 backgrounds, 0 corrupt: 100%|██████████| 1099/1099 [01:13<00:00, 14.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/.shortcut-targets-by-id/1I9_eaK3PIyivJvWadTz1JG5Vk0YGYwEz/dataset/VisDrone2019-DET-train/images/9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1I9_eaK3PIyivJvWadTz1JG5Vk0YGYwEz/dataset/VisDrone2019-DET-train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1I9_eaK3PIyivJvWadTz1JG5Vk0YGYwEz/dataset/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|██████████| 548/548 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/exp3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00046875), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/exp3\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      2.88G      1.996      3.367      1.092        654        640: 100%|██████████| 110/110 [00:27<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.179     0.0298      0.103     0.0637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      3.53G      1.882      2.099      1.034        760        640: 100%|██████████| 110/110 [00:11<00:00,  9.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.278     0.0596      0.165     0.0928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      4.06G      1.832       1.85      1.028        838        640: 100%|██████████| 110/110 [00:10<00:00, 10.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.272     0.0485      0.155      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      4.15G      1.759      1.712      1.018        825        640: 100%|██████████| 110/110 [00:10<00:00, 10.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:02<00:00,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.366     0.0534      0.209      0.143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      3.72G      1.723      1.644       1.01        465        640: 100%|██████████| 110/110 [00:10<00:00, 10.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.367     0.0534      0.209      0.144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      4.65G      1.696      1.581     0.9994       1105        640: 100%|██████████| 110/110 [00:10<00:00, 10.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.385      0.064      0.225      0.156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      5.04G      1.682      1.554     0.9985        548        640: 100%|██████████| 110/110 [00:10<00:00, 10.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.375     0.0623      0.217      0.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      3.13G      1.677       1.53     0.9927        644        640: 100%|██████████| 110/110 [00:10<00:00, 10.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.503     0.0474      0.274      0.174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      4.44G      1.651      1.485     0.9885        861        640: 100%|██████████| 110/110 [00:10<00:00, 10.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.482     0.0637      0.273      0.187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      4.45G      1.669      1.487     0.9937        648        640: 100%|██████████| 110/110 [00:11<00:00,  9.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.535     0.0776      0.305      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      3.81G      1.655      1.473     0.9858        721        640: 100%|██████████| 110/110 [00:10<00:00, 10.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.535     0.0925      0.315      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      3.56G      1.638       1.41     0.9801        692        640: 100%|██████████| 110/110 [00:11<00:00,  9.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.543     0.0923      0.316       0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      3.53G      1.637      1.416     0.9795        800        640: 100%|██████████| 110/110 [00:10<00:00, 10.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.591     0.0705       0.33      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      3.39G      1.618        1.4     0.9794        925        640: 100%|██████████| 110/110 [00:10<00:00, 10.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:02<00:00,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.532     0.0697        0.3      0.206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      3.61G      1.615       1.39      0.974        920        640: 100%|██████████| 110/110 [00:10<00:00, 10.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.534     0.0861      0.311      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      3.52G      1.604      1.364     0.9694        675        640: 100%|██████████| 110/110 [00:10<00:00, 10.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.561     0.0949      0.327       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100       3.1G      1.615      1.364     0.9812        501        640: 100%|██████████| 110/110 [00:10<00:00, 10.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.554     0.0846      0.318      0.209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100       3.8G       1.59      1.339     0.9718        655        640: 100%|██████████| 110/110 [00:10<00:00, 10.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.558     0.0985      0.325      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      4.89G      1.564      1.325     0.9665        705        640: 100%|██████████| 110/110 [00:10<00:00, 10.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.567      0.111      0.337       0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      3.62G      1.597       1.32     0.9702        694        640: 100%|██████████| 110/110 [00:11<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.583     0.0865      0.333      0.225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      3.69G      1.568      1.303     0.9666        688        640: 100%|██████████| 110/110 [00:10<00:00, 10.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.678      0.103       0.39      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      3.99G      1.562      1.295     0.9656        749        640: 100%|██████████| 110/110 [00:10<00:00, 10.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.589      0.096      0.342      0.231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      3.55G      1.562      1.286      0.966        733        640: 100%|██████████| 110/110 [00:10<00:00, 10.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.586     0.0971      0.342      0.231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      3.83G      1.585      1.293     0.9628        602        640: 100%|██████████| 110/110 [00:10<00:00, 10.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.541     0.0975      0.319      0.209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      3.74G      1.521       1.25      0.956        778        640: 100%|██████████| 110/110 [00:11<00:00,  9.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.54      0.105      0.323      0.217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      3.69G       1.56      1.253     0.9642        400        640: 100%|██████████| 110/110 [00:10<00:00, 10.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.539     0.0804       0.31      0.223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      2.79G      1.568      1.267     0.9614        814        640: 100%|██████████| 110/110 [00:10<00:00, 10.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.57      0.115      0.344      0.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      3.23G      1.528      1.235     0.9525        415        640: 100%|██████████| 110/110 [00:10<00:00, 10.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.584      0.105      0.347      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      3.68G      1.548      1.238     0.9574        639        640: 100%|██████████| 110/110 [00:10<00:00, 10.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.606      0.105      0.357      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      3.96G      1.538      1.244     0.9535        722        640: 100%|██████████| 110/110 [00:11<00:00,  9.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.57       0.11      0.341      0.228\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      3.67G      1.564      1.237     0.9533        687        640: 100%|██████████| 110/110 [00:11<00:00,  9.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.618      0.107      0.364      0.243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      3.03G      1.518      1.205     0.9489        695        640: 100%|██████████| 110/110 [00:10<00:00, 10.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.605       0.11      0.355      0.241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      3.57G      1.528      1.214     0.9532        923        640: 100%|██████████| 110/110 [00:10<00:00, 10.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.584      0.121      0.354       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      4.09G      1.518       1.21     0.9514        603        640: 100%|██████████| 110/110 [00:10<00:00, 10.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.691     0.0959      0.394      0.276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      4.98G      1.541      1.205     0.9483        621        640: 100%|██████████| 110/110 [00:10<00:00, 10.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:02<00:00,  9.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.602      0.114      0.357      0.243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      3.87G      1.517      1.204     0.9522        828        640: 100%|██████████| 110/110 [00:10<00:00, 10.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.594      0.119      0.357      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      3.73G      1.501      1.184     0.9469        780        640: 100%|██████████| 110/110 [00:10<00:00, 10.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.634      0.109      0.374      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100      4.68G      1.508      1.174     0.9473        668        640: 100%|██████████| 110/110 [00:11<00:00,  9.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.57      0.129      0.348       0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      3.88G      1.509      1.175     0.9433        786        640: 100%|██████████| 110/110 [00:10<00:00, 10.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.615      0.119      0.367      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      3.12G      1.511      1.177     0.9497        536        640: 100%|██████████| 110/110 [00:10<00:00, 10.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.585       0.11      0.349      0.234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      3.15G      1.499      1.169     0.9459        711        640: 100%|██████████| 110/110 [00:11<00:00,  9.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.615       0.11      0.361      0.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      4.48G      1.487      1.157      0.945        913        640: 100%|██████████| 110/110 [00:10<00:00, 10.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.638        0.1      0.368      0.248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      3.46G      1.508      1.169     0.9441        752        640: 100%|██████████| 110/110 [00:11<00:00,  9.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.63      0.117      0.374      0.254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100      3.29G      1.493      1.151     0.9408        998        640: 100%|██████████| 110/110 [00:10<00:00, 10.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.646      0.113       0.38      0.263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      3.64G      1.486      1.139     0.9416        780        640: 100%|██████████| 110/110 [00:10<00:00, 10.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.619      0.111      0.365      0.247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      4.45G      1.485      1.139     0.9424        576        640: 100%|██████████| 110/110 [00:10<00:00, 10.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.684      0.104      0.394      0.263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      4.08G      1.495      1.152     0.9408        753        640: 100%|██████████| 110/110 [00:10<00:00, 10.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.663      0.107      0.385      0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      3.33G      1.483      1.133     0.9397        894        640: 100%|██████████| 110/110 [00:10<00:00, 10.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.667      0.109      0.386       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      3.59G       1.49      1.129     0.9416        838        640: 100%|██████████| 110/110 [00:10<00:00, 10.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.614      0.136      0.376      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      3.81G      1.491      1.131     0.9388        748        640: 100%|██████████| 110/110 [00:10<00:00, 10.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.71      0.114      0.411       0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      3.69G      1.455      1.095     0.9319        619        640: 100%|██████████| 110/110 [00:11<00:00,  9.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.668      0.122      0.395      0.253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      3.76G      1.471      1.104     0.9394        820        640: 100%|██████████| 110/110 [00:11<00:00,  9.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.679      0.136      0.407      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100      4.33G      1.452      1.103     0.9329        763        640: 100%|██████████| 110/110 [00:10<00:00, 10.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.631      0.123      0.377      0.246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      4.32G      1.473      1.108     0.9362        570        640: 100%|██████████| 110/110 [00:10<00:00, 10.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.643      0.125      0.383      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100      3.48G      1.465      1.094     0.9354        469        640: 100%|██████████| 110/110 [00:10<00:00, 10.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.665      0.128      0.396      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      4.28G      1.487      1.119     0.9375        779        640: 100%|██████████| 110/110 [00:11<00:00,  9.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.627       0.13      0.378      0.249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      4.02G       1.46      1.102      0.936        846        640: 100%|██████████| 110/110 [00:10<00:00, 10.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.658      0.123       0.39      0.247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      4.23G      1.472      1.096     0.9363        606        640: 100%|██████████| 110/110 [00:10<00:00, 10.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.639      0.117      0.378      0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100      4.22G      1.437      1.087     0.9297        890        640: 100%|██████████| 110/110 [00:10<00:00, 10.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.635       0.12      0.379      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      3.35G      1.461      1.087       0.93        570        640: 100%|██████████| 110/110 [00:10<00:00, 10.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.629      0.136      0.383      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100      3.64G      1.451      1.079     0.9336       1149        640: 100%|██████████| 110/110 [00:10<00:00, 10.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.572      0.142      0.356      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      3.66G      1.407      1.057     0.9235        463        640: 100%|██████████| 110/110 [00:10<00:00, 10.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  7.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.598      0.133      0.363       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      4.08G      1.436      1.061     0.9288        945        640: 100%|██████████| 110/110 [00:11<00:00,  9.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.676      0.117      0.395      0.264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100       3.8G      1.434      1.059     0.9296        681        640: 100%|██████████| 110/110 [00:10<00:00, 10.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.655      0.134      0.395      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100         3G      1.435       1.06      0.924        648        640: 100%|██████████| 110/110 [00:10<00:00, 10.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.682      0.125      0.403      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      2.89G      1.449       1.07     0.9252       1178        640: 100%|██████████| 110/110 [00:10<00:00, 10.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.663      0.132      0.398       0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100       3.7G      1.432      1.052     0.9264        488        640: 100%|██████████| 110/110 [00:10<00:00, 10.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.617      0.124      0.371      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100      4.88G      1.434      1.055     0.9282        872        640: 100%|██████████| 110/110 [00:10<00:00, 10.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.636      0.132      0.384       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100      2.95G      1.446      1.049     0.9283        520        640: 100%|██████████| 110/110 [00:11<00:00,  9.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.621       0.13      0.377      0.248\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100      3.09G      1.427      1.041     0.9271        680        640: 100%|██████████| 110/110 [00:10<00:00, 10.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.627      0.135      0.382       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      4.08G       1.42      1.042     0.9272        660        640: 100%|██████████| 110/110 [00:10<00:00, 10.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.631      0.137      0.384      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100      4.09G      1.429      1.041     0.9238        797        640: 100%|██████████| 110/110 [00:10<00:00, 10.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.627      0.139      0.383      0.247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      6.13G      1.414      1.033     0.9267        476        640: 100%|██████████| 110/110 [00:11<00:00,  9.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.614      0.142       0.38      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100      2.74G      1.432      1.047     0.9291        532        640: 100%|██████████| 110/110 [00:10<00:00, 10.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.639       0.14      0.389      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100      4.09G       1.42      1.034     0.9224        765        640: 100%|██████████| 110/110 [00:10<00:00, 10.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.653      0.131      0.391      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100      3.69G      1.405      1.026     0.9214        431        640: 100%|██████████| 110/110 [00:10<00:00, 10.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.649      0.135      0.393      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100      3.12G      1.421      1.023     0.9243        514        640: 100%|██████████| 110/110 [00:11<00:00,  9.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.633      0.138      0.386      0.254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100      4.41G      1.404      1.017     0.9214        908        640: 100%|██████████| 110/110 [00:10<00:00, 10.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.644      0.136      0.391      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100      3.21G      1.414      1.019     0.9212        918        640: 100%|██████████| 110/110 [00:10<00:00, 10.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.654      0.142      0.397      0.261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100      3.87G      1.392      1.009     0.9228        789        640: 100%|██████████| 110/110 [00:10<00:00, 10.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.635      0.137      0.386      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100      3.18G      1.417      1.014      0.923        598        640: 100%|██████████| 110/110 [00:10<00:00, 10.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.65       0.14      0.393       0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100      5.22G      1.393      1.003     0.9164        805        640: 100%|██████████| 110/110 [00:11<00:00,  9.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.643      0.138      0.391      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100      3.17G      1.411      1.014     0.9211        468        640: 100%|██████████| 110/110 [00:11<00:00,  9.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.657      0.138      0.397      0.262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100      3.68G      1.404      1.003     0.9183        733        640: 100%|██████████| 110/110 [00:10<00:00, 10.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.647      0.137      0.393      0.256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100       3.8G       1.41     0.9995     0.9179        635        640: 100%|██████████| 110/110 [00:11<00:00,  9.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.662      0.132      0.396      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100      4.64G      1.383     0.9901      0.917        691        640: 100%|██████████| 110/110 [00:10<00:00, 10.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.648      0.143      0.395      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100      3.71G      1.399      0.995     0.9173        552        640: 100%|██████████| 110/110 [00:10<00:00, 10.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.644      0.147      0.396      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100      3.07G      1.413     0.9942     0.9174        849        640: 100%|██████████| 110/110 [00:10<00:00, 10.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.654      0.143      0.398      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100      3.67G      1.381      0.984     0.9162        641        640: 100%|██████████| 110/110 [00:10<00:00, 10.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.657      0.146      0.401      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100      3.71G      1.428      1.008     0.9223        551        640: 100%|██████████| 110/110 [00:11<00:00,  9.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.645      0.139      0.392      0.255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100      2.93G      1.401      1.011     0.9242        391        640: 100%|██████████| 110/110 [00:20<00:00,  5.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.626      0.143      0.383      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100      3.35G      1.379     0.9849     0.9163        705        640: 100%|██████████| 110/110 [00:10<00:00, 10.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.623      0.145      0.382      0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100      3.16G      1.363     0.9614     0.9147        295        640: 100%|██████████| 110/110 [00:11<00:00,  9.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.653       0.14      0.395       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100      2.75G      1.358     0.9616      0.917        441        640: 100%|██████████| 110/110 [00:10<00:00, 10.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.644      0.139       0.39      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100      2.65G      1.352     0.9538     0.9139        582        640: 100%|██████████| 110/110 [00:10<00:00, 10.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.64      0.142       0.39      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100      3.15G      1.347     0.9462     0.9132        151        640: 100%|██████████| 110/110 [00:10<00:00, 10.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.643       0.14      0.391      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100      3.19G      1.347     0.9437     0.9125        404        640: 100%|██████████| 110/110 [00:10<00:00, 10.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.647      0.138      0.392      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100      2.67G      1.351     0.9527     0.9113        439        640: 100%|██████████| 110/110 [00:10<00:00, 10.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  9.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.638      0.144       0.39      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100       3.1G       1.35     0.9461     0.9127        600        640: 100%|██████████| 110/110 [00:10<00:00, 10.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.625      0.144      0.384      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100      2.49G      1.336     0.9356     0.9114        440        640: 100%|██████████| 110/110 [00:10<00:00, 10.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:03<00:00,  8.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759      0.635       0.14      0.387      0.257\n",
            "\n",
            "100 epochs completed in 0.428 hours.\n",
            "Optimizer stripped from runs/detect/exp3/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/exp3/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/exp3/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.48 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:18<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        548      38759       0.69     0.0958      0.393      0.276\n",
            "            pedestrian        520       8844      0.847     0.0746       0.46       0.26\n",
            "                people        482       5125       0.73      0.018      0.373       0.16\n",
            "               bicycle        364       1287          0          0          0          0\n",
            "                   car        515      14064      0.877      0.482      0.683      0.518\n",
            "                   van        421       1975      0.748     0.0765       0.41      0.341\n",
            "                 truck        266        750      0.708     0.0613      0.378      0.293\n",
            "              tricycle        337       1045      0.525     0.0201      0.271      0.214\n",
            "       awning-tricycle        220        532          1    0.00564      0.503      0.402\n",
            "                   bus        131        251      0.754      0.171       0.47      0.367\n",
            "                 motor        485       4886       0.71     0.0485      0.377      0.206\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "results = model.train(data=\"VisDrone.yaml\", epochs=100, imgsz=640, weight_decay=0.0005, dropout=0.5, conf=0.45, iou=0.45, batch=10, verbose=True, name='exp', val=True, save=True, amp = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W7WUNs58rWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tz6ktd48rNw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZQ_UpzF8rJx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdI26cs98rCZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s97Yxykjg5RL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXCLdzNhC49x"
      },
      "source": [
        "**OBJECT COUNTING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npZtF9rb4vX-",
        "outputId": "33e268c5-d9a6-4ee4-8855-7807c307dc21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "Polygon Counter Initiated.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\n",
            "Collecting lapx>=0.5.2\n",
            "  Downloading lapx-0.5.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 12.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: Cython>=0.29.32 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (1.25.2)\n",
            "Installing collected packages: lapx\n",
            "Successfully installed lapx-0.5.8\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 9.0s, installed 1 package: ['lapx>=0.5.2']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "0: 384x640 2 persons, 193.5ms\n",
            "Speed: 5.8ms preprocess, 193.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.9ms\n",
            "Speed: 4.6ms preprocess, 149.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.5ms\n",
            "Speed: 4.1ms preprocess, 150.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 145.1ms\n",
            "Speed: 3.8ms preprocess, 145.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.7ms\n",
            "Speed: 3.6ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 140.2ms\n",
            "Speed: 3.5ms preprocess, 140.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 157.8ms\n",
            "Speed: 3.9ms preprocess, 157.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.9ms\n",
            "Speed: 4.3ms preprocess, 150.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.1ms\n",
            "Speed: 3.8ms preprocess, 150.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.4ms\n",
            "Speed: 4.2ms preprocess, 146.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.1ms\n",
            "Speed: 5.2ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 164.7ms\n",
            "Speed: 4.6ms preprocess, 164.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.7ms\n",
            "Speed: 3.7ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.6ms\n",
            "Speed: 4.9ms preprocess, 150.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.1ms\n",
            "Speed: 5.5ms preprocess, 143.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 164.3ms\n",
            "Speed: 6.1ms preprocess, 164.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 159.1ms\n",
            "Speed: 3.8ms preprocess, 159.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.3ms\n",
            "Speed: 3.7ms preprocess, 147.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.8ms\n",
            "Speed: 3.8ms preprocess, 150.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.4ms\n",
            "Speed: 4.2ms preprocess, 146.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 230.8ms\n",
            "Speed: 3.7ms preprocess, 230.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 218.8ms\n",
            "Speed: 4.0ms preprocess, 218.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 222.8ms\n",
            "Speed: 4.3ms preprocess, 222.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 237.7ms\n",
            "Speed: 3.8ms preprocess, 237.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 240.2ms\n",
            "Speed: 4.1ms preprocess, 240.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 227.4ms\n",
            "Speed: 3.9ms preprocess, 227.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 239.5ms\n",
            "Speed: 3.7ms preprocess, 239.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 226.1ms\n",
            "Speed: 3.9ms preprocess, 226.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 221.6ms\n",
            "Speed: 3.9ms preprocess, 221.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 208.2ms\n",
            "Speed: 3.9ms preprocess, 208.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 252.2ms\n",
            "Speed: 4.1ms preprocess, 252.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 222.6ms\n",
            "Speed: 3.7ms preprocess, 222.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 230.4ms\n",
            "Speed: 4.6ms preprocess, 230.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 207.3ms\n",
            "Speed: 3.9ms preprocess, 207.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.9ms\n",
            "Speed: 4.9ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.2ms\n",
            "Speed: 4.2ms preprocess, 151.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.9ms\n",
            "Speed: 4.7ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 165.5ms\n",
            "Speed: 3.8ms preprocess, 165.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.5ms\n",
            "Speed: 4.1ms preprocess, 144.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 147.6ms\n",
            "Speed: 5.0ms preprocess, 147.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.2ms\n",
            "Speed: 3.5ms preprocess, 143.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.8ms\n",
            "Speed: 4.1ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 162.1ms\n",
            "Speed: 5.3ms preprocess, 162.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.7ms\n",
            "Speed: 5.9ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.8ms\n",
            "Speed: 3.8ms preprocess, 151.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.4ms\n",
            "Speed: 3.8ms preprocess, 146.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.8ms\n",
            "Speed: 3.8ms preprocess, 151.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.0ms\n",
            "Speed: 3.6ms preprocess, 148.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.4ms\n",
            "Speed: 4.9ms preprocess, 149.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 155.7ms\n",
            "Speed: 3.6ms preprocess, 155.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 155.2ms\n",
            "Speed: 4.4ms preprocess, 155.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 158.5ms\n",
            "Speed: 4.0ms preprocess, 158.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.0ms\n",
            "Speed: 5.9ms preprocess, 148.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.9ms\n",
            "Speed: 4.2ms preprocess, 154.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.1ms\n",
            "Speed: 4.1ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.4ms\n",
            "Speed: 4.6ms preprocess, 148.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.2ms\n",
            "Speed: 4.7ms preprocess, 146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.3ms\n",
            "Speed: 3.5ms preprocess, 146.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.7ms\n",
            "Speed: 3.6ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.6ms\n",
            "Speed: 3.6ms preprocess, 156.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 160.0ms\n",
            "Speed: 3.7ms preprocess, 160.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.6ms\n",
            "Speed: 3.7ms preprocess, 146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.1ms\n",
            "Speed: 3.7ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.1ms\n",
            "Speed: 3.7ms preprocess, 147.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 159.0ms\n",
            "Speed: 4.0ms preprocess, 159.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 164.1ms\n",
            "Speed: 4.5ms preprocess, 164.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.4ms\n",
            "Speed: 3.8ms preprocess, 143.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.6ms\n",
            "Speed: 3.7ms preprocess, 147.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 152.2ms\n",
            "Speed: 3.7ms preprocess, 152.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.1ms\n",
            "Speed: 3.6ms preprocess, 149.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.4ms\n",
            "Speed: 4.6ms preprocess, 152.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.1ms\n",
            "Speed: 4.4ms preprocess, 143.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.0ms\n",
            "Speed: 4.9ms preprocess, 143.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.0ms\n",
            "Speed: 4.3ms preprocess, 158.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 167.9ms\n",
            "Speed: 4.5ms preprocess, 167.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.7ms\n",
            "Speed: 4.5ms preprocess, 149.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.9ms\n",
            "Speed: 3.7ms preprocess, 149.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 164.4ms\n",
            "Speed: 4.0ms preprocess, 164.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 244.3ms\n",
            "Speed: 3.9ms preprocess, 244.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 230.8ms\n",
            "Speed: 4.9ms preprocess, 230.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 220.5ms\n",
            "Speed: 4.3ms preprocess, 220.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.4ms\n",
            "Speed: 3.7ms preprocess, 222.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 232.6ms\n",
            "Speed: 5.3ms preprocess, 232.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 229.7ms\n",
            "Speed: 3.8ms preprocess, 229.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.4ms\n",
            "Speed: 3.9ms preprocess, 222.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 232.6ms\n",
            "Speed: 4.3ms preprocess, 232.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 228.5ms\n",
            "Speed: 4.3ms preprocess, 228.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 218.2ms\n",
            "Speed: 3.8ms preprocess, 218.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 246.4ms\n",
            "Speed: 3.8ms preprocess, 246.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 243.4ms\n",
            "Speed: 4.0ms preprocess, 243.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 231.1ms\n",
            "Speed: 3.8ms preprocess, 231.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 165.0ms\n",
            "Speed: 3.8ms preprocess, 165.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 umbrella, 141.4ms\n",
            "Speed: 5.4ms preprocess, 141.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 umbrella, 150.6ms\n",
            "Speed: 3.7ms preprocess, 150.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 145.8ms\n",
            "Speed: 4.5ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 145.2ms\n",
            "Speed: 5.1ms preprocess, 145.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 umbrella, 171.0ms\n",
            "Speed: 3.8ms preprocess, 171.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 umbrella, 162.3ms\n",
            "Speed: 4.7ms preprocess, 162.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 148.7ms\n",
            "Speed: 3.8ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 154.1ms\n",
            "Speed: 3.7ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 145.6ms\n",
            "Speed: 3.5ms preprocess, 145.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 144.4ms\n",
            "Speed: 4.0ms preprocess, 144.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 143.8ms\n",
            "Speed: 3.8ms preprocess, 143.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 146.9ms\n",
            "Speed: 3.6ms preprocess, 146.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 147.1ms\n",
            "Speed: 3.8ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 156.6ms\n",
            "Speed: 3.6ms preprocess, 156.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 144.2ms\n",
            "Speed: 3.6ms preprocess, 144.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.3ms\n",
            "Speed: 3.6ms preprocess, 151.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.2ms\n",
            "Speed: 4.1ms preprocess, 144.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.5ms\n",
            "Speed: 3.8ms preprocess, 149.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 162.9ms\n",
            "Speed: 3.8ms preprocess, 162.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 152.8ms\n",
            "Speed: 3.9ms preprocess, 152.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 151.7ms\n",
            "Speed: 4.8ms preprocess, 151.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 147.7ms\n",
            "Speed: 3.7ms preprocess, 147.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 147.5ms\n",
            "Speed: 4.6ms preprocess, 147.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.6ms\n",
            "Speed: 4.8ms preprocess, 148.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 151.4ms\n",
            "Speed: 3.9ms preprocess, 151.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 146.9ms\n",
            "Speed: 4.9ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 151.7ms\n",
            "Speed: 3.9ms preprocess, 151.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.9ms\n",
            "Speed: 4.4ms preprocess, 150.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.1ms\n",
            "Speed: 4.9ms preprocess, 149.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 167.0ms\n",
            "Speed: 4.2ms preprocess, 167.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 149.4ms\n",
            "Speed: 4.6ms preprocess, 149.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 150.0ms\n",
            "Speed: 3.6ms preprocess, 150.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 146.8ms\n",
            "Speed: 3.6ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 160.0ms\n",
            "Speed: 3.6ms preprocess, 160.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 157.2ms\n",
            "Speed: 4.5ms preprocess, 157.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.2ms\n",
            "Speed: 5.1ms preprocess, 146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 143.5ms\n",
            "Speed: 3.6ms preprocess, 143.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 horse, 143.7ms\n",
            "Speed: 4.0ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 horse, 153.0ms\n",
            "Speed: 4.5ms preprocess, 153.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 144.0ms\n",
            "Speed: 3.7ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.0ms\n",
            "Speed: 4.0ms preprocess, 150.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 150.6ms\n",
            "Speed: 3.6ms preprocess, 150.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 143.6ms\n",
            "Speed: 3.5ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 142.6ms\n",
            "Speed: 3.9ms preprocess, 142.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 147.1ms\n",
            "Speed: 4.3ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 145.7ms\n",
            "Speed: 5.0ms preprocess, 145.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 162.7ms\n",
            "Speed: 4.5ms preprocess, 162.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 233.3ms\n",
            "Speed: 5.5ms preprocess, 233.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 horse, 234.7ms\n",
            "Speed: 6.0ms preprocess, 234.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 horse, 217.1ms\n",
            "Speed: 4.0ms preprocess, 217.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 228.4ms\n",
            "Speed: 4.0ms preprocess, 228.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 235.9ms\n",
            "Speed: 3.8ms preprocess, 235.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.3ms\n",
            "Speed: 5.1ms preprocess, 223.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 227.2ms\n",
            "Speed: 4.5ms preprocess, 227.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 238.4ms\n",
            "Speed: 4.0ms preprocess, 238.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 213.0ms\n",
            "Speed: 3.7ms preprocess, 213.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 217.8ms\n",
            "Speed: 5.2ms preprocess, 217.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 231.2ms\n",
            "Speed: 4.0ms preprocess, 231.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 222.8ms\n",
            "Speed: 3.9ms preprocess, 222.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 207.4ms\n",
            "Speed: 3.9ms preprocess, 207.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.9ms\n",
            "Speed: 4.4ms preprocess, 150.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 162.0ms\n",
            "Speed: 4.5ms preprocess, 162.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 144.1ms\n",
            "Speed: 3.8ms preprocess, 144.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 152.8ms\n",
            "Speed: 3.7ms preprocess, 152.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.7ms\n",
            "Speed: 4.3ms preprocess, 149.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 155.7ms\n",
            "Speed: 3.7ms preprocess, 155.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 160.0ms\n",
            "Speed: 4.4ms preprocess, 160.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.9ms\n",
            "Speed: 3.7ms preprocess, 144.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.8ms\n",
            "Speed: 5.1ms preprocess, 147.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 148.9ms\n",
            "Speed: 3.6ms preprocess, 148.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.2ms\n",
            "Speed: 5.9ms preprocess, 147.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 155.7ms\n",
            "Speed: 4.7ms preprocess, 155.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 142.8ms\n",
            "Speed: 3.7ms preprocess, 142.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.8ms\n",
            "Speed: 5.6ms preprocess, 147.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.8ms\n",
            "Speed: 3.9ms preprocess, 148.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.0ms\n",
            "Speed: 5.3ms preprocess, 147.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.5ms\n",
            "Speed: 3.7ms preprocess, 143.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.9ms\n",
            "Speed: 3.6ms preprocess, 152.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 147.2ms\n",
            "Speed: 4.0ms preprocess, 147.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 154.2ms\n",
            "Speed: 3.7ms preprocess, 154.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 147.2ms\n",
            "Speed: 4.0ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 149.9ms\n",
            "Speed: 3.7ms preprocess, 149.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.1ms\n",
            "Speed: 3.7ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.3ms\n",
            "Speed: 3.7ms preprocess, 150.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.3ms\n",
            "Speed: 3.7ms preprocess, 145.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 159.1ms\n",
            "Speed: 4.2ms preprocess, 159.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.7ms\n",
            "Speed: 4.1ms preprocess, 146.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.7ms\n",
            "Speed: 3.9ms preprocess, 149.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 145.8ms\n",
            "Speed: 3.9ms preprocess, 145.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 165.4ms\n",
            "Speed: 4.3ms preprocess, 165.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 236.7ms\n",
            "Speed: 6.6ms preprocess, 236.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 253.3ms\n",
            "Speed: 4.5ms preprocess, 253.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 244.8ms\n",
            "Speed: 8.0ms preprocess, 244.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 166.0ms\n",
            "Speed: 3.7ms preprocess, 166.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.2ms\n",
            "Speed: 4.1ms preprocess, 149.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.0ms\n",
            "Speed: 3.6ms preprocess, 148.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.3ms\n",
            "Speed: 4.1ms preprocess, 150.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.6ms\n",
            "Speed: 3.8ms preprocess, 151.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 159.8ms\n",
            "Speed: 4.8ms preprocess, 159.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 145.3ms\n",
            "Speed: 4.4ms preprocess, 145.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 146.0ms\n",
            "Speed: 4.5ms preprocess, 146.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 143.6ms\n",
            "Speed: 3.9ms preprocess, 143.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 140.9ms\n",
            "Speed: 3.8ms preprocess, 140.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 153.2ms\n",
            "Speed: 4.1ms preprocess, 153.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 154.6ms\n",
            "Speed: 3.7ms preprocess, 154.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 220.3ms\n",
            "Speed: 3.9ms preprocess, 220.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 223.2ms\n",
            "Speed: 4.2ms preprocess, 223.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 229.9ms\n",
            "Speed: 4.1ms preprocess, 229.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 237.1ms\n",
            "Speed: 4.1ms preprocess, 237.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 314.4ms\n",
            "Speed: 3.7ms preprocess, 314.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 232.8ms\n",
            "Speed: 4.0ms preprocess, 232.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 221.7ms\n",
            "Speed: 5.9ms preprocess, 221.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 224.0ms\n",
            "Speed: 3.7ms preprocess, 224.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 228.0ms\n",
            "Speed: 3.8ms preprocess, 228.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 225.8ms\n",
            "Speed: 3.8ms preprocess, 225.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 217.6ms\n",
            "Speed: 4.0ms preprocess, 217.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 225.4ms\n",
            "Speed: 3.8ms preprocess, 225.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 223.5ms\n",
            "Speed: 3.8ms preprocess, 223.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 235.4ms\n",
            "Speed: 5.4ms preprocess, 235.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 225.3ms\n",
            "Speed: 3.8ms preprocess, 225.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 162.9ms\n",
            "Speed: 3.9ms preprocess, 162.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.2ms\n",
            "Speed: 4.2ms preprocess, 148.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 163.6ms\n",
            "Speed: 3.8ms preprocess, 163.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 144.7ms\n",
            "Speed: 4.7ms preprocess, 144.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 143.9ms\n",
            "Speed: 4.1ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 144.5ms\n",
            "Speed: 3.4ms preprocess, 144.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 142.4ms\n",
            "Speed: 3.6ms preprocess, 142.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 151.6ms\n",
            "Speed: 6.7ms preprocess, 151.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.4ms\n",
            "Speed: 4.2ms preprocess, 149.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 140.7ms\n",
            "Speed: 4.1ms preprocess, 140.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.8ms\n",
            "Speed: 3.5ms preprocess, 143.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 138.8ms\n",
            "Speed: 4.2ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 151.0ms\n",
            "Speed: 4.3ms preprocess, 151.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 156.3ms\n",
            "Speed: 4.3ms preprocess, 156.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 149.2ms\n",
            "Speed: 3.9ms preprocess, 149.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 146.9ms\n",
            "Speed: 5.1ms preprocess, 146.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 147.3ms\n",
            "Speed: 5.0ms preprocess, 147.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 149.2ms\n",
            "Speed: 3.7ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 145.2ms\n",
            "Speed: 4.3ms preprocess, 145.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 149.2ms\n",
            "Speed: 3.2ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 149.8ms\n",
            "Speed: 4.5ms preprocess, 149.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 151.5ms\n",
            "Speed: 3.8ms preprocess, 151.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 156.9ms\n",
            "Speed: 4.2ms preprocess, 156.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 149.7ms\n",
            "Speed: 4.9ms preprocess, 149.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 150.9ms\n",
            "Speed: 3.6ms preprocess, 150.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 143.9ms\n",
            "Speed: 4.3ms preprocess, 143.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 143.4ms\n",
            "Speed: 3.7ms preprocess, 143.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 160.5ms\n",
            "Speed: 3.8ms preprocess, 160.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 148.1ms\n",
            "Speed: 4.0ms preprocess, 148.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 146.9ms\n",
            "Speed: 4.0ms preprocess, 146.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 146.0ms\n",
            "Speed: 3.8ms preprocess, 146.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 trains, 154.8ms\n",
            "Speed: 4.0ms preprocess, 154.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 151.6ms\n",
            "Speed: 5.7ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 156.9ms\n",
            "Speed: 3.7ms preprocess, 156.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 141.1ms\n",
            "Speed: 4.6ms preprocess, 141.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 149.6ms\n",
            "Speed: 4.0ms preprocess, 149.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 151.8ms\n",
            "Speed: 5.2ms preprocess, 151.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 163.0ms\n",
            "Speed: 4.1ms preprocess, 163.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 179.6ms\n",
            "Speed: 3.7ms preprocess, 179.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 143.4ms\n",
            "Speed: 4.2ms preprocess, 143.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 152.4ms\n",
            "Speed: 4.0ms preprocess, 152.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 148.6ms\n",
            "Speed: 5.5ms preprocess, 148.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 149.4ms\n",
            "Speed: 4.1ms preprocess, 149.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 trains, 142.5ms\n",
            "Speed: 3.6ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 trains, 149.1ms\n",
            "Speed: 4.1ms preprocess, 149.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 147.0ms\n",
            "Speed: 5.6ms preprocess, 147.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 150.6ms\n",
            "Speed: 3.9ms preprocess, 150.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 196.1ms\n",
            "Speed: 4.7ms preprocess, 196.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 239.9ms\n",
            "Speed: 3.9ms preprocess, 239.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 238.3ms\n",
            "Speed: 3.7ms preprocess, 238.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 trains, 218.2ms\n",
            "Speed: 4.0ms preprocess, 218.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 trains, 228.2ms\n",
            "Speed: 3.9ms preprocess, 228.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 trains, 244.3ms\n",
            "Speed: 4.1ms preprocess, 244.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 trains, 221.4ms\n",
            "Speed: 3.9ms preprocess, 221.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 train, 217.6ms\n",
            "Speed: 3.7ms preprocess, 217.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 train, 220.0ms\n",
            "Speed: 8.2ms preprocess, 220.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 216.4ms\n",
            "Speed: 4.0ms preprocess, 216.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 236.1ms\n",
            "Speed: 6.3ms preprocess, 236.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 231.4ms\n",
            "Speed: 3.8ms preprocess, 231.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 239.9ms\n",
            "Speed: 3.7ms preprocess, 239.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 183.3ms\n",
            "Speed: 4.0ms preprocess, 183.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.3ms\n",
            "Speed: 4.3ms preprocess, 142.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 158.0ms\n",
            "Speed: 4.4ms preprocess, 158.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 158.1ms\n",
            "Speed: 5.3ms preprocess, 158.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.7ms\n",
            "Speed: 3.8ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.9ms\n",
            "Speed: 4.3ms preprocess, 142.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.4ms\n",
            "Speed: 3.3ms preprocess, 151.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.1ms\n",
            "Speed: 4.5ms preprocess, 147.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 155.8ms\n",
            "Speed: 5.2ms preprocess, 155.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.8ms\n",
            "Speed: 4.0ms preprocess, 148.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.1ms\n",
            "Speed: 3.7ms preprocess, 152.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.3ms\n",
            "Speed: 3.8ms preprocess, 151.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 161.8ms\n",
            "Speed: 4.2ms preprocess, 161.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.6ms\n",
            "Speed: 4.5ms preprocess, 146.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 158.2ms\n",
            "Speed: 4.4ms preprocess, 158.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 148.1ms\n",
            "Speed: 4.3ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 142.5ms\n",
            "Speed: 3.9ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 164.4ms\n",
            "Speed: 4.0ms preprocess, 164.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 trains, 148.7ms\n",
            "Speed: 4.6ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 trains, 152.9ms\n",
            "Speed: 4.4ms preprocess, 152.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 151.2ms\n",
            "Speed: 5.3ms preprocess, 151.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 158.7ms\n",
            "Speed: 4.2ms preprocess, 158.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 145.8ms\n",
            "Speed: 4.0ms preprocess, 145.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 146.6ms\n",
            "Speed: 4.1ms preprocess, 146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 155.9ms\n",
            "Speed: 4.2ms preprocess, 155.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 152.4ms\n",
            "Speed: 4.6ms preprocess, 152.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 162.7ms\n",
            "Speed: 4.6ms preprocess, 162.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 152.0ms\n",
            "Speed: 4.1ms preprocess, 152.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 148.8ms\n",
            "Speed: 4.1ms preprocess, 148.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 145.6ms\n",
            "Speed: 4.1ms preprocess, 145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 149.8ms\n",
            "Speed: 4.4ms preprocess, 149.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 153.9ms\n",
            "Speed: 3.9ms preprocess, 153.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 143.8ms\n",
            "Speed: 4.2ms preprocess, 143.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 148.4ms\n",
            "Speed: 4.2ms preprocess, 148.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cow, 146.3ms\n",
            "Speed: 4.6ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cow, 147.1ms\n",
            "Speed: 4.0ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 1 cow, 150.5ms\n",
            "Speed: 4.2ms preprocess, 150.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 1 cow, 146.9ms\n",
            "Speed: 4.1ms preprocess, 146.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.5ms\n",
            "Speed: 4.4ms preprocess, 148.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.4ms\n",
            "Speed: 4.1ms preprocess, 154.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.1ms\n",
            "Speed: 4.3ms preprocess, 158.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 143.7ms\n",
            "Speed: 4.4ms preprocess, 143.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 144.7ms\n",
            "Speed: 4.1ms preprocess, 144.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 159.2ms\n",
            "Speed: 4.6ms preprocess, 159.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.7ms\n",
            "Speed: 3.6ms preprocess, 151.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 240.9ms\n",
            "Speed: 5.8ms preprocess, 240.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 226.5ms\n",
            "Speed: 3.7ms preprocess, 226.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 218.8ms\n",
            "Speed: 6.5ms preprocess, 218.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 222.2ms\n",
            "Speed: 3.9ms preprocess, 222.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 241.2ms\n",
            "Speed: 4.0ms preprocess, 241.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 224.8ms\n",
            "Speed: 3.8ms preprocess, 224.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 261.3ms\n",
            "Speed: 3.7ms preprocess, 261.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 220.8ms\n",
            "Speed: 6.0ms preprocess, 220.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 217.7ms\n",
            "Speed: 4.0ms preprocess, 217.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 239.3ms\n",
            "Speed: 4.2ms preprocess, 239.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 229.2ms\n",
            "Speed: 5.6ms preprocess, 229.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 trains, 225.7ms\n",
            "Speed: 4.2ms preprocess, 225.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 trains, 241.6ms\n",
            "Speed: 4.1ms preprocess, 241.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 trains, 146.4ms\n",
            "Speed: 3.9ms preprocess, 146.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 141.7ms\n",
            "Speed: 3.6ms preprocess, 141.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 144.5ms\n",
            "Speed: 3.7ms preprocess, 144.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 145.1ms\n",
            "Speed: 3.9ms preprocess, 145.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 160.0ms\n",
            "Speed: 4.0ms preprocess, 160.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 trains, 151.6ms\n",
            "Speed: 4.2ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 145.4ms\n",
            "Speed: 3.9ms preprocess, 145.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 144.5ms\n",
            "Speed: 4.0ms preprocess, 144.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 trains, 155.2ms\n",
            "Speed: 4.2ms preprocess, 155.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 154.0ms\n",
            "Speed: 3.9ms preprocess, 154.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 144.7ms\n",
            "Speed: 3.9ms preprocess, 144.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 150.3ms\n",
            "Speed: 4.3ms preprocess, 150.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 140.3ms\n",
            "Speed: 5.0ms preprocess, 140.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 144.9ms\n",
            "Speed: 3.9ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 trains, 142.1ms\n",
            "Speed: 4.0ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 144.1ms\n",
            "Speed: 3.9ms preprocess, 144.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 139.1ms\n",
            "Speed: 4.5ms preprocess, 139.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 157.2ms\n",
            "Speed: 3.9ms preprocess, 157.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 trains, 151.8ms\n",
            "Speed: 3.9ms preprocess, 151.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 trains, 148.2ms\n",
            "Speed: 4.1ms preprocess, 148.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 144.9ms\n",
            "Speed: 3.6ms preprocess, 144.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 151.7ms\n",
            "Speed: 4.0ms preprocess, 151.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 144.8ms\n",
            "Speed: 3.8ms preprocess, 144.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 165.7ms\n",
            "Speed: 3.5ms preprocess, 165.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 142.4ms\n",
            "Speed: 4.1ms preprocess, 142.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 151.9ms\n",
            "Speed: 4.5ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.5ms\n",
            "Speed: 7.2ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.9ms\n",
            "Speed: 3.9ms preprocess, 143.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 159.1ms\n",
            "Speed: 3.7ms preprocess, 159.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 144.5ms\n",
            "Speed: 3.6ms preprocess, 144.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 155.6ms\n",
            "Speed: 4.6ms preprocess, 155.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 162.6ms\n",
            "Speed: 3.7ms preprocess, 162.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.6ms\n",
            "Speed: 3.8ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.9ms\n",
            "Speed: 4.1ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 154.5ms\n",
            "Speed: 4.1ms preprocess, 154.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 151.1ms\n",
            "Speed: 3.8ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.6ms\n",
            "Speed: 4.0ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 159.2ms\n",
            "Speed: 3.6ms preprocess, 159.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.6ms\n",
            "Speed: 4.7ms preprocess, 142.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 149.6ms\n",
            "Speed: 3.7ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 144.6ms\n",
            "Speed: 3.7ms preprocess, 144.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 train, 146.3ms\n",
            "Speed: 3.7ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 156.2ms\n",
            "Speed: 3.8ms preprocess, 156.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 145.4ms\n",
            "Speed: 3.8ms preprocess, 145.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 142.7ms\n",
            "Speed: 4.6ms preprocess, 142.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 144.5ms\n",
            "Speed: 4.3ms preprocess, 144.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 244.6ms\n",
            "Speed: 4.7ms preprocess, 244.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 220.8ms\n",
            "Speed: 4.0ms preprocess, 220.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 214.8ms\n",
            "Speed: 3.8ms preprocess, 214.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 217.1ms\n",
            "Speed: 3.9ms preprocess, 217.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 235.6ms\n",
            "Speed: 8.9ms preprocess, 235.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 241.1ms\n",
            "Speed: 3.8ms preprocess, 241.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 221.0ms\n",
            "Speed: 3.8ms preprocess, 221.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 231.7ms\n",
            "Speed: 3.8ms preprocess, 231.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 220.3ms\n",
            "Speed: 4.4ms preprocess, 220.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 216.1ms\n",
            "Speed: 3.7ms preprocess, 216.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 232.9ms\n",
            "Speed: 3.9ms preprocess, 232.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 219.4ms\n",
            "Speed: 3.8ms preprocess, 219.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 202.9ms\n",
            "Speed: 4.0ms preprocess, 202.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 137.6ms\n",
            "Speed: 5.0ms preprocess, 137.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.4ms\n",
            "Speed: 4.9ms preprocess, 143.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.4ms\n",
            "Speed: 5.2ms preprocess, 146.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.4ms\n",
            "Speed: 3.7ms preprocess, 148.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.7ms\n",
            "Speed: 3.7ms preprocess, 151.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 163.0ms\n",
            "Speed: 3.6ms preprocess, 163.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.7ms\n",
            "Speed: 3.6ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.2ms\n",
            "Speed: 3.6ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 140.6ms\n",
            "Speed: 3.7ms preprocess, 140.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.1ms\n",
            "Speed: 3.7ms preprocess, 143.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 162.9ms\n",
            "Speed: 3.6ms preprocess, 162.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.7ms\n",
            "Speed: 3.7ms preprocess, 149.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.7ms\n",
            "Speed: 3.7ms preprocess, 144.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.9ms\n",
            "Speed: 3.7ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 157.1ms\n",
            "Speed: 3.8ms preprocess, 157.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.8ms\n",
            "Speed: 3.9ms preprocess, 153.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.6ms\n",
            "Speed: 3.8ms preprocess, 148.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.7ms\n",
            "Speed: 3.8ms preprocess, 146.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.8ms\n",
            "Speed: 3.2ms preprocess, 143.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 163.7ms\n",
            "Speed: 4.4ms preprocess, 163.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 147.6ms\n",
            "Speed: 5.9ms preprocess, 147.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.9ms\n",
            "Speed: 4.1ms preprocess, 142.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.7ms\n",
            "Speed: 3.5ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 145.4ms\n",
            "Speed: 4.2ms preprocess, 145.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 155.1ms\n",
            "Speed: 3.4ms preprocess, 155.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.6ms\n",
            "Speed: 3.7ms preprocess, 146.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 157.9ms\n",
            "Speed: 3.8ms preprocess, 157.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.6ms\n",
            "Speed: 3.7ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.6ms\n",
            "Speed: 3.7ms preprocess, 148.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.4ms\n",
            "Speed: 3.9ms preprocess, 156.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.3ms\n",
            "Speed: 3.8ms preprocess, 144.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.3ms\n",
            "Speed: 3.8ms preprocess, 144.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 3.8ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 166.8ms\n",
            "Speed: 4.7ms preprocess, 166.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 4.1ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 155.0ms\n",
            "Speed: 4.1ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 141.5ms\n",
            "Speed: 3.9ms preprocess, 141.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.2ms\n",
            "Speed: 3.7ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 162.7ms\n",
            "Speed: 4.1ms preprocess, 162.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 146.9ms\n",
            "Speed: 4.4ms preprocess, 146.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 140.7ms\n",
            "Speed: 4.0ms preprocess, 140.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 142.3ms\n",
            "Speed: 4.0ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 144.1ms\n",
            "Speed: 3.8ms preprocess, 144.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.7ms\n",
            "Speed: 3.8ms preprocess, 151.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.2ms\n",
            "Speed: 4.3ms preprocess, 144.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 223.3ms\n",
            "Speed: 6.0ms preprocess, 223.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 230.4ms\n",
            "Speed: 4.2ms preprocess, 230.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.9ms\n",
            "Speed: 4.0ms preprocess, 223.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 213.7ms\n",
            "Speed: 3.9ms preprocess, 213.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 233.4ms\n",
            "Speed: 3.9ms preprocess, 233.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 229.2ms\n",
            "Speed: 3.9ms preprocess, 229.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 215.5ms\n",
            "Speed: 4.1ms preprocess, 215.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.6ms\n",
            "Speed: 3.9ms preprocess, 222.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 235.8ms\n",
            "Speed: 4.2ms preprocess, 235.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 213.8ms\n",
            "Speed: 3.7ms preprocess, 213.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 255.1ms\n",
            "Speed: 6.5ms preprocess, 255.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 237.2ms\n",
            "Speed: 9.1ms preprocess, 237.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.1ms\n",
            "Speed: 3.6ms preprocess, 222.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 172.5ms\n",
            "Speed: 4.6ms preprocess, 172.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.8ms\n",
            "Speed: 3.9ms preprocess, 143.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 191.1ms\n",
            "Speed: 4.0ms preprocess, 191.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 165.1ms\n",
            "Speed: 3.8ms preprocess, 165.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.9ms\n",
            "Speed: 4.2ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.2ms\n",
            "Speed: 4.3ms preprocess, 148.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 157.1ms\n",
            "Speed: 8.0ms preprocess, 157.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.4ms\n",
            "Speed: 3.8ms preprocess, 152.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.1ms\n",
            "Speed: 3.6ms preprocess, 148.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 141.1ms\n",
            "Speed: 4.7ms preprocess, 141.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.3ms\n",
            "Speed: 3.7ms preprocess, 156.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.5ms\n",
            "Speed: 4.0ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.0ms\n",
            "Speed: 3.9ms preprocess, 143.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.6ms\n",
            "Speed: 6.3ms preprocess, 150.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.0ms\n",
            "Speed: 3.7ms preprocess, 151.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 162.7ms\n",
            "Speed: 3.6ms preprocess, 162.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.1ms\n",
            "Speed: 3.5ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.4ms\n",
            "Speed: 4.6ms preprocess, 153.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 157.1ms\n",
            "Speed: 5.0ms preprocess, 157.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.6ms\n",
            "Speed: 4.0ms preprocess, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 174.8ms\n",
            "Speed: 3.8ms preprocess, 174.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 223.6ms\n",
            "Speed: 4.0ms preprocess, 223.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 241.1ms\n",
            "Speed: 4.0ms preprocess, 241.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 220.6ms\n",
            "Speed: 3.9ms preprocess, 220.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 217.0ms\n",
            "Speed: 3.8ms preprocess, 217.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 239.1ms\n",
            "Speed: 3.9ms preprocess, 239.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 237.2ms\n",
            "Speed: 3.7ms preprocess, 237.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 233.0ms\n",
            "Speed: 4.1ms preprocess, 233.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 225.1ms\n",
            "Speed: 4.2ms preprocess, 225.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 219.3ms\n",
            "Speed: 4.6ms preprocess, 219.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 232.0ms\n",
            "Speed: 4.0ms preprocess, 232.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 245.0ms\n",
            "Speed: 4.0ms preprocess, 245.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 225.6ms\n",
            "Speed: 6.1ms preprocess, 225.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 207.1ms\n",
            "Speed: 4.3ms preprocess, 207.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.9ms\n",
            "Speed: 5.6ms preprocess, 147.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.9ms\n",
            "Speed: 5.8ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.4ms\n",
            "Speed: 4.2ms preprocess, 147.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 160.7ms\n",
            "Speed: 3.7ms preprocess, 160.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 237.8ms\n",
            "Speed: 4.2ms preprocess, 237.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 223.3ms\n",
            "Speed: 3.9ms preprocess, 223.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 338.6ms\n",
            "Speed: 3.7ms preprocess, 338.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 237.1ms\n",
            "Speed: 4.0ms preprocess, 237.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.4ms\n",
            "Speed: 4.0ms preprocess, 221.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 229.7ms\n",
            "Speed: 5.9ms preprocess, 229.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 223.2ms\n",
            "Speed: 3.9ms preprocess, 223.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 218.4ms\n",
            "Speed: 5.8ms preprocess, 218.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 228.5ms\n",
            "Speed: 7.6ms preprocess, 228.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 222.6ms\n",
            "Speed: 4.1ms preprocess, 222.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 223.8ms\n",
            "Speed: 4.0ms preprocess, 223.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 224.5ms\n",
            "Speed: 3.8ms preprocess, 224.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 252.5ms\n",
            "Speed: 3.9ms preprocess, 252.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.7ms\n",
            "Speed: 3.8ms preprocess, 144.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.4ms\n",
            "Speed: 4.7ms preprocess, 151.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.9ms\n",
            "Speed: 4.3ms preprocess, 149.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 159.4ms\n",
            "Speed: 4.4ms preprocess, 159.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.9ms\n",
            "Speed: 4.2ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.9ms\n",
            "Speed: 4.8ms preprocess, 145.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.1ms\n",
            "Speed: 3.4ms preprocess, 144.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.9ms\n",
            "Speed: 4.4ms preprocess, 153.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.5ms\n",
            "Speed: 3.8ms preprocess, 149.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.2ms\n",
            "Speed: 3.6ms preprocess, 152.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.8ms\n",
            "Speed: 3.7ms preprocess, 152.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.7ms\n",
            "Speed: 4.9ms preprocess, 142.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 166.8ms\n",
            "Speed: 3.8ms preprocess, 166.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.3ms\n",
            "Speed: 4.0ms preprocess, 142.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.1ms\n",
            "Speed: 6.9ms preprocess, 150.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.8ms\n",
            "Speed: 4.3ms preprocess, 145.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.2ms\n",
            "Speed: 4.1ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.9ms\n",
            "Speed: 3.9ms preprocess, 147.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.0ms\n",
            "Speed: 4.7ms preprocess, 153.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.3ms\n",
            "Speed: 5.8ms preprocess, 151.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.2ms\n",
            "Speed: 4.5ms preprocess, 154.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 162.6ms\n",
            "Speed: 3.6ms preprocess, 162.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.5ms\n",
            "Speed: 3.9ms preprocess, 148.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.3ms\n",
            "Speed: 4.7ms preprocess, 156.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.3ms\n",
            "Speed: 3.6ms preprocess, 150.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 163.1ms\n",
            "Speed: 3.7ms preprocess, 163.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.2ms\n",
            "Speed: 3.9ms preprocess, 149.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.6ms\n",
            "Speed: 6.5ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.1ms\n",
            "Speed: 3.9ms preprocess, 150.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.2ms\n",
            "Speed: 3.6ms preprocess, 150.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 150.6ms\n",
            "Speed: 4.3ms preprocess, 150.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 151.5ms\n",
            "Speed: 4.0ms preprocess, 151.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 149.9ms\n",
            "Speed: 4.6ms preprocess, 149.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 148.3ms\n",
            "Speed: 3.8ms preprocess, 148.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 152.6ms\n",
            "Speed: 3.9ms preprocess, 152.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 166.2ms\n",
            "Speed: 4.8ms preprocess, 166.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 148.0ms\n",
            "Speed: 4.0ms preprocess, 148.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 148.2ms\n",
            "Speed: 4.5ms preprocess, 148.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 150.7ms\n",
            "Speed: 4.0ms preprocess, 150.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 171.2ms\n",
            "Speed: 4.5ms preprocess, 171.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 162.0ms\n",
            "Speed: 3.6ms preprocess, 162.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 146.2ms\n",
            "Speed: 3.6ms preprocess, 146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.2ms\n",
            "Speed: 3.6ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 train, 1 umbrella, 153.9ms\n",
            "Speed: 3.5ms preprocess, 153.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 200.2ms\n",
            "Speed: 3.9ms preprocess, 200.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 train, 220.5ms\n",
            "Speed: 5.8ms preprocess, 220.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 237.2ms\n",
            "Speed: 3.8ms preprocess, 237.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 215.3ms\n",
            "Speed: 3.9ms preprocess, 215.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 228.0ms\n",
            "Speed: 3.8ms preprocess, 228.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 sheep, 1 umbrella, 219.5ms\n",
            "Speed: 7.9ms preprocess, 219.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 sheep, 1 umbrella, 221.2ms\n",
            "Speed: 5.4ms preprocess, 221.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 sheep, 233.8ms\n",
            "Speed: 3.8ms preprocess, 233.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 221.7ms\n",
            "Speed: 3.8ms preprocess, 221.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 1 sheep, 210.0ms\n",
            "Speed: 6.9ms preprocess, 210.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 1 sheep, 225.1ms\n",
            "Speed: 3.6ms preprocess, 225.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 1 sheep, 222.4ms\n",
            "Speed: 9.7ms preprocess, 222.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 1 sheep, 228.8ms\n",
            "Speed: 5.4ms preprocess, 228.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 1 sheep, 233.3ms\n",
            "Speed: 12.2ms preprocess, 233.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 151.3ms\n",
            "Speed: 3.6ms preprocess, 151.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 149.5ms\n",
            "Speed: 3.8ms preprocess, 149.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 train, 149.9ms\n",
            "Speed: 3.8ms preprocess, 149.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 train, 144.3ms\n",
            "Speed: 4.1ms preprocess, 144.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 trains, 165.5ms\n",
            "Speed: 4.6ms preprocess, 165.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.3ms\n",
            "Speed: 4.0ms preprocess, 143.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.8ms\n",
            "Speed: 4.0ms preprocess, 146.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.9ms\n",
            "Speed: 4.7ms preprocess, 153.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 trains, 137.8ms\n",
            "Speed: 5.4ms preprocess, 137.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 trains, 143.7ms\n",
            "Speed: 5.1ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 trains, 142.3ms\n",
            "Speed: 4.8ms preprocess, 142.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 trains, 151.2ms\n",
            "Speed: 3.7ms preprocess, 151.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 train, 151.8ms\n",
            "Speed: 3.6ms preprocess, 151.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 train, 161.4ms\n",
            "Speed: 4.7ms preprocess, 161.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 train, 145.8ms\n",
            "Speed: 4.7ms preprocess, 145.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 trains, 149.4ms\n",
            "Speed: 4.4ms preprocess, 149.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 trains, 141.4ms\n",
            "Speed: 4.4ms preprocess, 141.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 trains, 148.5ms\n",
            "Speed: 3.7ms preprocess, 148.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 trains, 158.0ms\n",
            "Speed: 4.1ms preprocess, 158.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 trains, 149.1ms\n",
            "Speed: 4.5ms preprocess, 149.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 trains, 155.2ms\n",
            "Speed: 5.5ms preprocess, 155.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 trains, 141.8ms\n",
            "Speed: 4.0ms preprocess, 141.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 4 trains, 156.8ms\n",
            "Speed: 4.1ms preprocess, 156.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 trains, 152.3ms\n",
            "Speed: 4.3ms preprocess, 152.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 trains, 155.4ms\n",
            "Speed: 4.5ms preprocess, 155.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 trains, 146.9ms\n",
            "Speed: 5.3ms preprocess, 146.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 trains, 142.8ms\n",
            "Speed: 8.3ms preprocess, 142.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 trains, 159.7ms\n",
            "Speed: 4.0ms preprocess, 159.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 trains, 146.2ms\n",
            "Speed: 3.8ms preprocess, 146.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 trains, 145.7ms\n",
            "Speed: 4.4ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 trains, 143.7ms\n",
            "Speed: 3.5ms preprocess, 143.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 trains, 143.9ms\n",
            "Speed: 4.8ms preprocess, 143.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 trains, 163.9ms\n",
            "Speed: 4.0ms preprocess, 163.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 154.4ms\n",
            "Speed: 6.2ms preprocess, 154.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 train, 150.3ms\n",
            "Speed: 3.7ms preprocess, 150.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 trains, 143.7ms\n",
            "Speed: 3.7ms preprocess, 143.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 trains, 153.4ms\n",
            "Speed: 3.5ms preprocess, 153.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 trains, 153.5ms\n",
            "Speed: 3.8ms preprocess, 153.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 trains, 150.7ms\n",
            "Speed: 3.6ms preprocess, 150.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 trains, 146.7ms\n",
            "Speed: 4.6ms preprocess, 146.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 141.4ms\n",
            "Speed: 5.1ms preprocess, 141.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 151.7ms\n",
            "Speed: 5.7ms preprocess, 151.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 145.4ms\n",
            "Speed: 4.2ms preprocess, 145.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 139.4ms\n",
            "Speed: 5.2ms preprocess, 139.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 141.9ms\n",
            "Speed: 4.8ms preprocess, 141.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trains, 236.6ms\n",
            "Speed: 9.8ms preprocess, 236.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 trains, 228.4ms\n",
            "Speed: 4.0ms preprocess, 228.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 trains, 218.1ms\n",
            "Speed: 6.1ms preprocess, 218.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 trains, 220.3ms\n",
            "Speed: 3.8ms preprocess, 220.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 trains, 239.6ms\n",
            "Speed: 3.9ms preprocess, 239.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 trains, 1 cow, 228.8ms\n",
            "Speed: 3.7ms preprocess, 228.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 trains, 1 cow, 241.9ms\n",
            "Speed: 9.0ms preprocess, 241.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 252.3ms\n",
            "Speed: 5.4ms preprocess, 252.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 215.3ms\n",
            "Speed: 4.3ms preprocess, 215.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 218.0ms\n",
            "Speed: 4.2ms preprocess, 218.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 243.0ms\n",
            "Speed: 4.0ms preprocess, 243.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 trains, 236.3ms\n",
            "Speed: 5.0ms preprocess, 236.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 227.5ms\n",
            "Speed: 4.3ms preprocess, 227.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 146.0ms\n",
            "Speed: 6.8ms preprocess, 146.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.9ms\n",
            "Speed: 4.3ms preprocess, 151.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.4ms\n",
            "Speed: 3.7ms preprocess, 151.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.9ms\n",
            "Speed: 4.0ms preprocess, 142.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 151.0ms\n",
            "Speed: 4.0ms preprocess, 151.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 160.3ms\n",
            "Speed: 3.8ms preprocess, 160.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 147.4ms\n",
            "Speed: 4.2ms preprocess, 147.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 144.7ms\n",
            "Speed: 5.9ms preprocess, 144.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 142.4ms\n",
            "Speed: 4.3ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 150.6ms\n",
            "Speed: 3.7ms preprocess, 150.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 160.8ms\n",
            "Speed: 3.5ms preprocess, 160.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 traffic light, 144.8ms\n",
            "Speed: 4.1ms preprocess, 144.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 145.3ms\n",
            "Speed: 4.7ms preprocess, 145.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 149.7ms\n",
            "Speed: 5.7ms preprocess, 149.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 traffic light, 152.4ms\n",
            "Speed: 4.7ms preprocess, 152.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 traffic light, 143.0ms\n",
            "Speed: 3.6ms preprocess, 143.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 traffic light, 145.6ms\n",
            "Speed: 3.5ms preprocess, 145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 train, 150.3ms\n",
            "Speed: 4.4ms preprocess, 150.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 train, 145.8ms\n",
            "Speed: 3.7ms preprocess, 145.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 146.7ms\n",
            "Speed: 4.7ms preprocess, 146.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 143.5ms\n",
            "Speed: 3.7ms preprocess, 143.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 140.8ms\n",
            "Speed: 4.0ms preprocess, 140.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 143.8ms\n",
            "Speed: 3.8ms preprocess, 143.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 156.9ms\n",
            "Speed: 4.4ms preprocess, 156.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 158.9ms\n",
            "Speed: 4.5ms preprocess, 158.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 153.7ms\n",
            "Speed: 3.8ms preprocess, 153.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 150.5ms\n",
            "Speed: 3.9ms preprocess, 150.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 155.8ms\n",
            "Speed: 3.6ms preprocess, 155.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 153.8ms\n",
            "Speed: 3.8ms preprocess, 153.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 potted plant, 154.5ms\n",
            "Speed: 4.6ms preprocess, 154.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 150.9ms\n",
            "Speed: 4.4ms preprocess, 150.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 153.6ms\n",
            "Speed: 7.2ms preprocess, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 147.9ms\n",
            "Speed: 3.8ms preprocess, 147.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 157.8ms\n",
            "Speed: 3.7ms preprocess, 157.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 152.5ms\n",
            "Speed: 4.7ms preprocess, 152.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 161.5ms\n",
            "Speed: 6.5ms preprocess, 161.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 155.4ms\n",
            "Speed: 3.8ms preprocess, 155.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 149.6ms\n",
            "Speed: 4.5ms preprocess, 149.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 156.5ms\n",
            "Speed: 4.3ms preprocess, 156.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 149.6ms\n",
            "Speed: 4.6ms preprocess, 149.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 149.6ms\n",
            "Speed: 4.7ms preprocess, 149.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 150.5ms\n",
            "Speed: 4.5ms preprocess, 150.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 142.0ms\n",
            "Speed: 3.9ms preprocess, 142.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 155.6ms\n",
            "Speed: 3.9ms preprocess, 155.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 149.3ms\n",
            "Speed: 3.7ms preprocess, 149.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 232.6ms\n",
            "Speed: 8.2ms preprocess, 232.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 231.5ms\n",
            "Speed: 3.9ms preprocess, 231.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.8ms\n",
            "Speed: 4.5ms preprocess, 223.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 215.7ms\n",
            "Speed: 3.8ms preprocess, 215.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 227.9ms\n",
            "Speed: 8.8ms preprocess, 227.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 229.4ms\n",
            "Speed: 4.0ms preprocess, 229.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.7ms\n",
            "Speed: 3.5ms preprocess, 222.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.4ms\n",
            "Speed: 3.8ms preprocess, 222.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 230.1ms\n",
            "Speed: 3.9ms preprocess, 230.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 215.5ms\n",
            "Speed: 3.7ms preprocess, 215.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 226.2ms\n",
            "Speed: 3.9ms preprocess, 226.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 254.7ms\n",
            "Speed: 3.8ms preprocess, 254.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 226.6ms\n",
            "Speed: 3.9ms preprocess, 226.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 216.8ms\n",
            "Speed: 5.7ms preprocess, 216.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 fire hydrant, 143.2ms\n",
            "Speed: 4.4ms preprocess, 143.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 fire hydrant, 161.8ms\n",
            "Speed: 4.0ms preprocess, 161.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.8ms\n",
            "Speed: 4.8ms preprocess, 148.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.0ms\n",
            "Speed: 4.5ms preprocess, 150.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 141.7ms\n",
            "Speed: 4.9ms preprocess, 141.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.3ms\n",
            "Speed: 4.6ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.8ms\n",
            "Speed: 4.6ms preprocess, 150.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.1ms\n",
            "Speed: 3.9ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.2ms\n",
            "Speed: 3.9ms preprocess, 156.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 bench, 148.3ms\n",
            "Speed: 3.8ms preprocess, 148.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 bench, 160.2ms\n",
            "Speed: 8.1ms preprocess, 160.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 161.3ms\n",
            "Speed: 3.6ms preprocess, 161.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 146.9ms\n",
            "Speed: 3.8ms preprocess, 146.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 210.0ms\n",
            "Speed: 5.0ms preprocess, 210.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.7ms\n",
            "Speed: 5.1ms preprocess, 156.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.6ms\n",
            "Speed: 3.7ms preprocess, 150.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 fire hydrant, 1 potted plant, 147.3ms\n",
            "Speed: 4.2ms preprocess, 147.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 fire hydrant, 1 potted plant, 142.0ms\n",
            "Speed: 4.0ms preprocess, 142.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 fire hydrant, 145.1ms\n",
            "Speed: 4.3ms preprocess, 145.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 fire hydrant, 159.5ms\n",
            "Speed: 3.8ms preprocess, 159.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 fire hydrant, 147.0ms\n",
            "Speed: 4.6ms preprocess, 147.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 fire hydrant, 145.5ms\n",
            "Speed: 4.1ms preprocess, 145.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 141.0ms\n",
            "Speed: 4.6ms preprocess, 141.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 154.8ms\n",
            "Speed: 4.5ms preprocess, 154.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 159.9ms\n",
            "Speed: 3.9ms preprocess, 159.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.1ms\n",
            "Speed: 3.6ms preprocess, 149.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 159.2ms\n",
            "Speed: 3.5ms preprocess, 159.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 140.4ms\n",
            "Speed: 4.2ms preprocess, 140.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.8ms\n",
            "Speed: 3.6ms preprocess, 146.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.8ms\n",
            "Speed: 5.2ms preprocess, 142.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.9ms\n",
            "Speed: 3.9ms preprocess, 146.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.5ms\n",
            "Speed: 4.3ms preprocess, 144.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.4ms\n",
            "Speed: 4.7ms preprocess, 147.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 164.1ms\n",
            "Speed: 7.3ms preprocess, 164.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.4ms\n",
            "Speed: 4.6ms preprocess, 145.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.7ms\n",
            "Speed: 5.8ms preprocess, 143.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.5ms\n",
            "Speed: 5.7ms preprocess, 143.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.4ms\n",
            "Speed: 4.2ms preprocess, 143.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 160.1ms\n",
            "Speed: 3.7ms preprocess, 160.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.2ms\n",
            "Speed: 3.8ms preprocess, 149.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.5ms\n",
            "Speed: 3.7ms preprocess, 144.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.8ms\n",
            "Speed: 3.9ms preprocess, 145.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.5ms\n",
            "Speed: 4.4ms preprocess, 156.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.2ms\n",
            "Speed: 3.9ms preprocess, 144.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 197.8ms\n",
            "Speed: 3.8ms preprocess, 197.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 230.6ms\n",
            "Speed: 4.7ms preprocess, 230.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 237.2ms\n",
            "Speed: 6.8ms preprocess, 237.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 fire hydrant, 216.1ms\n",
            "Speed: 3.8ms preprocess, 216.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 fire hydrant, 241.2ms\n",
            "Speed: 6.0ms preprocess, 241.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 238.4ms\n",
            "Speed: 3.9ms preprocess, 238.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 222.9ms\n",
            "Speed: 4.2ms preprocess, 222.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 220.3ms\n",
            "Speed: 3.7ms preprocess, 220.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 fire hydrant, 214.2ms\n",
            "Speed: 5.8ms preprocess, 214.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 218.1ms\n",
            "Speed: 3.6ms preprocess, 218.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 fire hydrants, 282.3ms\n",
            "Speed: 3.9ms preprocess, 282.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 fire hydrants, 226.2ms\n",
            "Speed: 5.4ms preprocess, 226.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 232.4ms\n",
            "Speed: 3.9ms preprocess, 232.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 233.6ms\n",
            "Speed: 4.0ms preprocess, 233.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 144.4ms\n",
            "Speed: 4.2ms preprocess, 144.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 142.2ms\n",
            "Speed: 3.8ms preprocess, 142.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 143.8ms\n",
            "Speed: 3.8ms preprocess, 143.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 153.8ms\n",
            "Speed: 3.8ms preprocess, 153.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 144.2ms\n",
            "Speed: 4.3ms preprocess, 144.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 146.7ms\n",
            "Speed: 3.5ms preprocess, 146.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 144.4ms\n",
            "Speed: 3.7ms preprocess, 144.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 144.8ms\n",
            "Speed: 3.7ms preprocess, 144.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 153.9ms\n",
            "Speed: 3.7ms preprocess, 153.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 153.7ms\n",
            "Speed: 4.1ms preprocess, 153.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 151.9ms\n",
            "Speed: 3.7ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 potted plants, 162.4ms\n",
            "Speed: 4.3ms preprocess, 162.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 potted plants, 152.3ms\n",
            "Speed: 3.5ms preprocess, 152.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 145.6ms\n",
            "Speed: 4.2ms preprocess, 145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 146.2ms\n",
            "Speed: 3.8ms preprocess, 146.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 139.1ms\n",
            "Speed: 4.5ms preprocess, 139.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 162.4ms\n",
            "Speed: 3.6ms preprocess, 162.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 144.6ms\n",
            "Speed: 3.7ms preprocess, 144.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 162.8ms\n",
            "Speed: 3.9ms preprocess, 162.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 153.0ms\n",
            "Speed: 4.3ms preprocess, 153.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 159.4ms\n",
            "Speed: 4.9ms preprocess, 159.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 145.7ms\n",
            "Speed: 4.6ms preprocess, 145.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 148.8ms\n",
            "Speed: 4.5ms preprocess, 148.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 143.4ms\n",
            "Speed: 4.5ms preprocess, 143.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 148.6ms\n",
            "Speed: 4.3ms preprocess, 148.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 157.3ms\n",
            "Speed: 4.3ms preprocess, 157.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.3ms\n",
            "Speed: 3.7ms preprocess, 152.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.9ms\n",
            "Speed: 3.6ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.9ms\n",
            "Speed: 4.0ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 143.9ms\n",
            "Speed: 4.2ms preprocess, 143.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 153.2ms\n",
            "Speed: 3.8ms preprocess, 153.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 153.5ms\n",
            "Speed: 4.0ms preprocess, 153.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 144.8ms\n",
            "Speed: 3.8ms preprocess, 144.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 141.8ms\n",
            "Speed: 4.0ms preprocess, 141.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.7ms\n",
            "Speed: 3.6ms preprocess, 151.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.0ms\n",
            "Speed: 5.3ms preprocess, 144.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.9ms\n",
            "Speed: 4.4ms preprocess, 148.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.4ms\n",
            "Speed: 3.6ms preprocess, 148.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.0ms\n",
            "Speed: 7.0ms preprocess, 149.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.2ms\n",
            "Speed: 7.3ms preprocess, 151.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 143.4ms\n",
            "Speed: 4.2ms preprocess, 143.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 148.7ms\n",
            "Speed: 3.7ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 148.7ms\n",
            "Speed: 3.7ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 157.1ms\n",
            "Speed: 4.4ms preprocess, 157.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 150.6ms\n",
            "Speed: 3.9ms preprocess, 150.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 239.9ms\n",
            "Speed: 4.5ms preprocess, 239.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 235.3ms\n",
            "Speed: 6.4ms preprocess, 235.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 239.7ms\n",
            "Speed: 3.7ms preprocess, 239.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 232.0ms\n",
            "Speed: 4.1ms preprocess, 232.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 233.6ms\n",
            "Speed: 3.8ms preprocess, 233.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 251.4ms\n",
            "Speed: 5.5ms preprocess, 251.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 227.0ms\n",
            "Speed: 5.2ms preprocess, 227.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 224.5ms\n",
            "Speed: 8.0ms preprocess, 224.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.1ms\n",
            "Speed: 4.2ms preprocess, 222.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 220.6ms\n",
            "Speed: 3.9ms preprocess, 220.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 228.7ms\n",
            "Speed: 3.8ms preprocess, 228.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 233.9ms\n",
            "Speed: 4.5ms preprocess, 233.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 236.3ms\n",
            "Speed: 5.2ms preprocess, 236.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 171.7ms\n",
            "Speed: 5.3ms preprocess, 171.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.4ms\n",
            "Speed: 4.0ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.2ms\n",
            "Speed: 3.9ms preprocess, 148.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 163.7ms\n",
            "Speed: 4.4ms preprocess, 163.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 3.7ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.1ms\n",
            "Speed: 3.9ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.3ms\n",
            "Speed: 4.0ms preprocess, 143.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 139.2ms\n",
            "Speed: 4.5ms preprocess, 139.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.8ms\n",
            "Speed: 4.3ms preprocess, 148.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 155.4ms\n",
            "Speed: 4.3ms preprocess, 155.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.3ms\n",
            "Speed: 4.0ms preprocess, 153.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.9ms\n",
            "Speed: 4.6ms preprocess, 154.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 160.9ms\n",
            "Speed: 4.0ms preprocess, 160.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.3ms\n",
            "Speed: 3.7ms preprocess, 148.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.2ms\n",
            "Speed: 4.0ms preprocess, 144.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 140.4ms\n",
            "Speed: 5.9ms preprocess, 140.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.9ms\n",
            "Speed: 4.3ms preprocess, 148.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 157.2ms\n",
            "Speed: 4.3ms preprocess, 157.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.9ms\n",
            "Speed: 4.0ms preprocess, 144.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.0ms\n",
            "Speed: 3.6ms preprocess, 147.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.4ms\n",
            "Speed: 4.1ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.3ms\n",
            "Speed: 3.8ms preprocess, 142.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.4ms\n",
            "Speed: 4.0ms preprocess, 150.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.1ms\n",
            "Speed: 3.9ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.0ms\n",
            "Speed: 4.5ms preprocess, 153.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.6ms\n",
            "Speed: 3.8ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 163.5ms\n",
            "Speed: 4.3ms preprocess, 163.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.2ms\n",
            "Speed: 3.8ms preprocess, 143.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.1ms\n",
            "Speed: 4.7ms preprocess, 154.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.7ms\n",
            "Speed: 8.2ms preprocess, 145.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 140.9ms\n",
            "Speed: 6.2ms preprocess, 140.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.8ms\n",
            "Speed: 4.1ms preprocess, 158.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 152.1ms\n",
            "Speed: 4.3ms preprocess, 152.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 155.0ms\n",
            "Speed: 3.7ms preprocess, 155.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 148.0ms\n",
            "Speed: 4.6ms preprocess, 148.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.3ms\n",
            "Speed: 4.0ms preprocess, 153.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.8ms\n",
            "Speed: 4.7ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.6ms\n",
            "Speed: 4.8ms preprocess, 150.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.1ms\n",
            "Speed: 4.2ms preprocess, 148.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.4ms\n",
            "Speed: 4.8ms preprocess, 150.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.5ms\n",
            "Speed: 3.8ms preprocess, 154.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 fire hydrant, 143.3ms\n",
            "Speed: 4.5ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 fire hydrant, 148.3ms\n",
            "Speed: 4.0ms preprocess, 148.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.2ms\n",
            "Speed: 4.4ms preprocess, 150.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.6ms\n",
            "Speed: 4.1ms preprocess, 153.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 202.6ms\n",
            "Speed: 3.8ms preprocess, 202.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 230.4ms\n",
            "Speed: 3.8ms preprocess, 230.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 215.9ms\n",
            "Speed: 3.8ms preprocess, 215.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 224.4ms\n",
            "Speed: 3.9ms preprocess, 224.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 213.1ms\n",
            "Speed: 6.3ms preprocess, 213.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 234.4ms\n",
            "Speed: 4.4ms preprocess, 234.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 254.3ms\n",
            "Speed: 3.9ms preprocess, 254.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 227.2ms\n",
            "Speed: 4.5ms preprocess, 227.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 226.9ms\n",
            "Speed: 7.7ms preprocess, 226.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.5ms\n",
            "Speed: 3.9ms preprocess, 223.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 222.4ms\n",
            "Speed: 4.3ms preprocess, 222.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 train, 226.8ms\n",
            "Speed: 4.5ms preprocess, 226.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 train, 234.6ms\n",
            "Speed: 4.0ms preprocess, 234.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 234.1ms\n",
            "Speed: 4.1ms preprocess, 234.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 164.4ms\n",
            "Speed: 4.5ms preprocess, 164.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.7ms\n",
            "Speed: 3.9ms preprocess, 146.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.2ms\n",
            "Speed: 3.7ms preprocess, 149.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 160.7ms\n",
            "Speed: 4.1ms preprocess, 160.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.2ms\n",
            "Speed: 13.0ms preprocess, 154.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.6ms\n",
            "Speed: 3.8ms preprocess, 148.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.4ms\n",
            "Speed: 3.6ms preprocess, 144.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.4ms\n",
            "Speed: 4.1ms preprocess, 147.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.1ms\n",
            "Speed: 4.1ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.7ms\n",
            "Speed: 4.4ms preprocess, 150.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.5ms\n",
            "Speed: 4.1ms preprocess, 143.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.6ms\n",
            "Speed: 4.1ms preprocess, 142.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.8ms\n",
            "Speed: 4.1ms preprocess, 156.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.5ms\n",
            "Speed: 4.0ms preprocess, 151.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.3ms\n",
            "Speed: 4.5ms preprocess, 148.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.3ms\n",
            "Speed: 3.8ms preprocess, 144.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.9ms\n",
            "Speed: 4.0ms preprocess, 147.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.7ms\n",
            "Speed: 4.3ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.0ms\n",
            "Speed: 4.0ms preprocess, 150.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.2ms\n",
            "Speed: 3.6ms preprocess, 145.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.6ms\n",
            "Speed: 3.7ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 158.1ms\n",
            "Speed: 3.7ms preprocess, 158.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.7ms\n",
            "Speed: 4.1ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.5ms\n",
            "Speed: 4.6ms preprocess, 152.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.8ms\n",
            "Speed: 4.7ms preprocess, 146.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.3ms\n",
            "Speed: 3.7ms preprocess, 149.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 166.0ms\n",
            "Speed: 4.1ms preprocess, 166.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.5ms\n",
            "Speed: 4.0ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 139.3ms\n",
            "Speed: 4.1ms preprocess, 139.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.8ms\n",
            "Speed: 4.2ms preprocess, 149.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.0ms\n",
            "Speed: 4.1ms preprocess, 146.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.2ms\n",
            "Speed: 4.2ms preprocess, 153.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.3ms\n",
            "Speed: 5.2ms preprocess, 149.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.9ms\n",
            "Speed: 4.4ms preprocess, 154.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.1ms\n",
            "Speed: 4.4ms preprocess, 146.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 162.6ms\n",
            "Speed: 4.4ms preprocess, 162.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.0ms\n",
            "Speed: 4.1ms preprocess, 150.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.2ms\n",
            "Speed: 4.2ms preprocess, 150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.8ms\n",
            "Speed: 3.9ms preprocess, 146.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 165.0ms\n",
            "Speed: 4.6ms preprocess, 165.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.1ms\n",
            "Speed: 4.0ms preprocess, 146.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.5ms\n",
            "Speed: 3.8ms preprocess, 144.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 144.6ms\n",
            "Speed: 4.3ms preprocess, 144.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.7ms\n",
            "Speed: 3.7ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 204.7ms\n",
            "Speed: 4.7ms preprocess, 204.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.4ms\n",
            "Speed: 4.0ms preprocess, 221.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.5ms\n",
            "Speed: 3.8ms preprocess, 221.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 230.8ms\n",
            "Speed: 3.9ms preprocess, 230.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 218.7ms\n",
            "Speed: 4.0ms preprocess, 218.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 221.7ms\n",
            "Speed: 4.0ms preprocess, 221.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 237.7ms\n",
            "Speed: 3.9ms preprocess, 237.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 219.8ms\n",
            "Speed: 3.8ms preprocess, 219.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 219.8ms\n",
            "Speed: 6.4ms preprocess, 219.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 241.5ms\n",
            "Speed: 4.1ms preprocess, 241.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 226.9ms\n",
            "Speed: 6.9ms preprocess, 226.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 229.2ms\n",
            "Speed: 3.9ms preprocess, 229.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 229.1ms\n",
            "Speed: 4.1ms preprocess, 229.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 226.9ms\n",
            "Speed: 4.6ms preprocess, 226.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.3ms\n",
            "Speed: 3.7ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 144.0ms\n",
            "Speed: 3.9ms preprocess, 144.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 145.9ms\n",
            "Speed: 4.5ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 160.8ms\n",
            "Speed: 3.7ms preprocess, 160.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.0ms\n",
            "Speed: 3.8ms preprocess, 146.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 152.4ms\n",
            "Speed: 3.7ms preprocess, 152.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 157.9ms\n",
            "Speed: 3.9ms preprocess, 157.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 155.0ms\n",
            "Speed: 3.6ms preprocess, 155.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 149.0ms\n",
            "Speed: 7.6ms preprocess, 149.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 148.0ms\n",
            "Speed: 3.9ms preprocess, 148.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 143.9ms\n",
            "Speed: 4.0ms preprocess, 143.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.3ms\n",
            "Speed: 3.9ms preprocess, 152.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 163.9ms\n",
            "Speed: 4.0ms preprocess, 163.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.0ms\n",
            "Speed: 4.1ms preprocess, 145.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 147.2ms\n",
            "Speed: 4.0ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.9ms\n",
            "Speed: 4.0ms preprocess, 158.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.8ms\n",
            "Speed: 4.2ms preprocess, 144.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 167.2ms\n",
            "Speed: 3.8ms preprocess, 167.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.0ms\n",
            "Speed: 3.9ms preprocess, 148.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 155.3ms\n",
            "Speed: 4.6ms preprocess, 155.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.2ms\n",
            "Speed: 5.4ms preprocess, 148.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 157.1ms\n",
            "Speed: 4.5ms preprocess, 157.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.0ms\n",
            "Speed: 3.9ms preprocess, 144.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.7ms\n",
            "Speed: 3.7ms preprocess, 153.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 187.5ms\n",
            "Speed: 4.5ms preprocess, 187.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.3ms\n",
            "Speed: 4.3ms preprocess, 223.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.3ms\n",
            "Speed: 4.1ms preprocess, 150.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.1ms\n",
            "Speed: 4.3ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.5ms\n",
            "Speed: 4.1ms preprocess, 152.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 146.8ms\n",
            "Speed: 4.9ms preprocess, 146.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 158.8ms\n",
            "Speed: 3.5ms preprocess, 158.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 157.9ms\n",
            "Speed: 4.8ms preprocess, 157.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 145.5ms\n",
            "Speed: 3.6ms preprocess, 145.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 151.6ms\n",
            "Speed: 3.9ms preprocess, 151.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 146.3ms\n",
            "Speed: 4.8ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 147.2ms\n",
            "Speed: 4.4ms preprocess, 147.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 149.1ms\n",
            "Speed: 3.8ms preprocess, 149.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.4ms\n",
            "Speed: 5.4ms preprocess, 154.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.4ms\n",
            "Speed: 4.4ms preprocess, 144.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.5ms\n",
            "Speed: 4.7ms preprocess, 158.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.4ms\n",
            "Speed: 4.0ms preprocess, 151.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 161.1ms\n",
            "Speed: 3.7ms preprocess, 161.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.0ms\n",
            "Speed: 7.1ms preprocess, 152.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 186.9ms\n",
            "Speed: 4.1ms preprocess, 186.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.1ms\n",
            "Speed: 7.8ms preprocess, 223.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 231.8ms\n",
            "Speed: 3.9ms preprocess, 231.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 215.8ms\n",
            "Speed: 4.2ms preprocess, 215.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 241.4ms\n",
            "Speed: 8.1ms preprocess, 241.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.9ms\n",
            "Speed: 8.3ms preprocess, 221.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.3ms\n",
            "Speed: 3.9ms preprocess, 221.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 233.3ms\n",
            "Speed: 4.0ms preprocess, 233.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 234.4ms\n",
            "Speed: 3.7ms preprocess, 234.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 214.9ms\n",
            "Speed: 4.7ms preprocess, 214.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 251.5ms\n",
            "Speed: 3.8ms preprocess, 251.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 236.2ms\n",
            "Speed: 4.1ms preprocess, 236.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 255.3ms\n",
            "Speed: 3.8ms preprocess, 255.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 236.8ms\n",
            "Speed: 4.1ms preprocess, 236.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.6ms\n",
            "Speed: 5.6ms preprocess, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 141.9ms\n",
            "Speed: 7.4ms preprocess, 141.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.2ms\n",
            "Speed: 4.1ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 194.4ms\n",
            "Speed: 3.6ms preprocess, 194.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.8ms\n",
            "Speed: 3.5ms preprocess, 146.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.5ms\n",
            "Speed: 3.7ms preprocess, 151.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.8ms\n",
            "Speed: 6.4ms preprocess, 151.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.1ms\n",
            "Speed: 4.1ms preprocess, 143.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.9ms\n",
            "Speed: 4.4ms preprocess, 158.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 141.5ms\n",
            "Speed: 4.5ms preprocess, 141.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.6ms\n",
            "Speed: 4.2ms preprocess, 151.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.3ms\n",
            "Speed: 3.7ms preprocess, 144.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.6ms\n",
            "Speed: 4.3ms preprocess, 153.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 157.1ms\n",
            "Speed: 3.8ms preprocess, 157.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.9ms\n",
            "Speed: 5.7ms preprocess, 144.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.2ms\n",
            "Speed: 4.2ms preprocess, 152.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.8ms\n",
            "Speed: 3.7ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 159.7ms\n",
            "Speed: 4.4ms preprocess, 159.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.6ms\n",
            "Speed: 5.1ms preprocess, 152.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.0ms\n",
            "Speed: 4.4ms preprocess, 150.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 141.4ms\n",
            "Speed: 4.8ms preprocess, 141.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.5ms\n",
            "Speed: 4.2ms preprocess, 147.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.7ms\n",
            "Speed: 3.9ms preprocess, 150.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.3ms\n",
            "Speed: 3.8ms preprocess, 146.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.7ms\n",
            "Speed: 4.1ms preprocess, 143.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.2ms\n",
            "Speed: 3.9ms preprocess, 142.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 167.4ms\n",
            "Speed: 4.0ms preprocess, 167.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.4ms\n",
            "Speed: 4.5ms preprocess, 151.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.0ms\n",
            "Speed: 4.2ms preprocess, 151.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.0ms\n",
            "Speed: 4.3ms preprocess, 146.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.4ms\n",
            "Speed: 4.4ms preprocess, 150.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.9ms\n",
            "Speed: 11.9ms preprocess, 156.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.2ms\n",
            "Speed: 4.2ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.6ms\n",
            "Speed: 4.2ms preprocess, 147.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.7ms\n",
            "Speed: 3.7ms preprocess, 150.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 163.1ms\n",
            "Speed: 3.8ms preprocess, 163.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 163.2ms\n",
            "Speed: 4.3ms preprocess, 163.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.9ms\n",
            "Speed: 5.0ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.4ms\n",
            "Speed: 3.7ms preprocess, 150.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 160.4ms\n",
            "Speed: 3.6ms preprocess, 160.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 165.3ms\n",
            "Speed: 4.4ms preprocess, 165.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.8ms\n",
            "Speed: 5.4ms preprocess, 151.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.9ms\n",
            "Speed: 4.0ms preprocess, 150.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 208.3ms\n",
            "Speed: 4.4ms preprocess, 208.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 237.7ms\n",
            "Speed: 6.3ms preprocess, 237.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 227.3ms\n",
            "Speed: 7.4ms preprocess, 227.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 227.3ms\n",
            "Speed: 4.1ms preprocess, 227.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 250.1ms\n",
            "Speed: 3.9ms preprocess, 250.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 241.4ms\n",
            "Speed: 7.2ms preprocess, 241.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 236.5ms\n",
            "Speed: 4.0ms preprocess, 236.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 232.1ms\n",
            "Speed: 7.2ms preprocess, 232.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 225.8ms\n",
            "Speed: 3.9ms preprocess, 225.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 251.7ms\n",
            "Speed: 5.8ms preprocess, 251.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 273.2ms\n",
            "Speed: 5.7ms preprocess, 273.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 263.7ms\n",
            "Speed: 3.9ms preprocess, 263.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 269.9ms\n",
            "Speed: 6.3ms preprocess, 269.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 288.4ms\n",
            "Speed: 9.1ms preprocess, 288.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 274.8ms\n",
            "Speed: 3.9ms preprocess, 274.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 270.2ms\n",
            "Speed: 3.7ms preprocess, 270.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 267.8ms\n",
            "Speed: 3.9ms preprocess, 267.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 242.9ms\n",
            "Speed: 8.6ms preprocess, 242.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.0ms\n",
            "Speed: 3.2ms preprocess, 222.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 240.5ms\n",
            "Speed: 3.8ms preprocess, 240.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 216.7ms\n",
            "Speed: 3.8ms preprocess, 216.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 220.3ms\n",
            "Speed: 3.8ms preprocess, 220.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 244.3ms\n",
            "Speed: 5.8ms preprocess, 244.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 249.3ms\n",
            "Speed: 3.8ms preprocess, 249.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 233.0ms\n",
            "Speed: 4.1ms preprocess, 233.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 219.0ms\n",
            "Speed: 5.7ms preprocess, 219.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 148.7ms\n",
            "Speed: 3.8ms preprocess, 148.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.1ms\n",
            "Speed: 3.8ms preprocess, 148.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 boat, 150.1ms\n",
            "Speed: 3.7ms preprocess, 150.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.1ms\n",
            "Speed: 4.5ms preprocess, 148.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.1ms\n",
            "Speed: 3.9ms preprocess, 145.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.9ms\n",
            "Speed: 4.1ms preprocess, 146.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.7ms\n",
            "Speed: 5.3ms preprocess, 153.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 3.5ms preprocess, 148.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.5ms\n",
            "Speed: 3.9ms preprocess, 158.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.1ms\n",
            "Speed: 4.7ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.0ms\n",
            "Speed: 3.8ms preprocess, 154.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.1ms\n",
            "Speed: 3.7ms preprocess, 150.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.5ms\n",
            "Speed: 3.7ms preprocess, 148.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 160.6ms\n",
            "Speed: 3.6ms preprocess, 160.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 155.6ms\n",
            "Speed: 4.4ms preprocess, 155.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.7ms\n",
            "Speed: 4.0ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.7ms\n",
            "Speed: 5.4ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 157.2ms\n",
            "Speed: 4.6ms preprocess, 157.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.5ms\n",
            "Speed: 4.4ms preprocess, 146.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 140.9ms\n",
            "Speed: 4.0ms preprocess, 140.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.0ms\n",
            "Speed: 4.1ms preprocess, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.1ms\n",
            "Speed: 4.1ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 175.4ms\n",
            "Speed: 4.3ms preprocess, 175.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.2ms\n",
            "Speed: 4.0ms preprocess, 150.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.2ms\n",
            "Speed: 3.6ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.3ms\n",
            "Speed: 4.2ms preprocess, 152.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.1ms\n",
            "Speed: 5.1ms preprocess, 142.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.7ms\n",
            "Speed: 3.5ms preprocess, 150.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.0ms\n",
            "Speed: 3.6ms preprocess, 143.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.0ms\n",
            "Speed: 3.5ms preprocess, 151.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.5ms\n",
            "Speed: 4.6ms preprocess, 143.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 168.4ms\n",
            "Speed: 3.7ms preprocess, 168.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 226.1ms\n",
            "Speed: 6.0ms preprocess, 226.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.3ms\n",
            "Speed: 3.8ms preprocess, 221.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 229.1ms\n",
            "Speed: 3.6ms preprocess, 229.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 212.3ms\n",
            "Speed: 3.9ms preprocess, 212.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 236.4ms\n",
            "Speed: 5.3ms preprocess, 236.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 250.2ms\n",
            "Speed: 3.6ms preprocess, 250.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 229.4ms\n",
            "Speed: 3.8ms preprocess, 229.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.7ms\n",
            "Speed: 3.8ms preprocess, 221.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 221.7ms\n",
            "Speed: 3.8ms preprocess, 221.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 237.1ms\n",
            "Speed: 3.7ms preprocess, 237.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 228.3ms\n",
            "Speed: 3.8ms preprocess, 228.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 226.2ms\n",
            "Speed: 9.2ms preprocess, 226.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 256.0ms\n",
            "Speed: 3.9ms preprocess, 256.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 222.1ms\n",
            "Speed: 4.0ms preprocess, 222.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 144.8ms\n",
            "Speed: 3.9ms preprocess, 144.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 148.6ms\n",
            "Speed: 4.3ms preprocess, 148.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 157.3ms\n",
            "Speed: 4.0ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.6ms\n",
            "Speed: 4.1ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.0ms\n",
            "Speed: 4.1ms preprocess, 152.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.8ms\n",
            "Speed: 3.8ms preprocess, 151.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.5ms\n",
            "Speed: 4.6ms preprocess, 144.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 163.5ms\n",
            "Speed: 3.9ms preprocess, 163.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.0ms\n",
            "Speed: 3.9ms preprocess, 147.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.8ms\n",
            "Speed: 4.4ms preprocess, 147.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.2ms\n",
            "Speed: 4.8ms preprocess, 150.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.2ms\n",
            "Speed: 4.0ms preprocess, 144.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.7ms\n",
            "Speed: 4.6ms preprocess, 145.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.1ms\n",
            "Speed: 4.4ms preprocess, 145.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 162.3ms\n",
            "Speed: 4.5ms preprocess, 162.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.1ms\n",
            "Speed: 5.3ms preprocess, 150.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 155.1ms\n",
            "Speed: 4.7ms preprocess, 155.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.5ms\n",
            "Speed: 4.0ms preprocess, 142.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.2ms\n",
            "Speed: 4.0ms preprocess, 148.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.0ms\n",
            "Speed: 4.4ms preprocess, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 4.5ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 160.6ms\n",
            "Speed: 3.7ms preprocess, 160.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.4ms\n",
            "Speed: 4.5ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.5ms\n",
            "Speed: 3.7ms preprocess, 151.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.6ms\n",
            "Speed: 4.6ms preprocess, 148.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 167.3ms\n",
            "Speed: 3.7ms preprocess, 167.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.9ms\n",
            "Speed: 4.1ms preprocess, 146.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.1ms\n",
            "Speed: 4.0ms preprocess, 145.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 3.7ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.0ms\n",
            "Speed: 3.6ms preprocess, 156.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 162.8ms\n",
            "Speed: 3.8ms preprocess, 162.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.5ms\n",
            "Speed: 4.3ms preprocess, 146.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 152.0ms\n",
            "Speed: 3.6ms preprocess, 152.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.9ms\n",
            "Speed: 4.1ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 176.5ms\n",
            "Speed: 3.6ms preprocess, 176.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.0ms\n",
            "Speed: 4.0ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.2ms\n",
            "Speed: 3.7ms preprocess, 153.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.1ms\n",
            "Speed: 3.6ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.3ms\n",
            "Speed: 3.6ms preprocess, 150.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 167.4ms\n",
            "Speed: 3.7ms preprocess, 167.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.1ms\n",
            "Speed: 4.0ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 160.3ms\n",
            "Speed: 3.7ms preprocess, 160.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.8ms\n",
            "Speed: 5.4ms preprocess, 146.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 171.0ms\n",
            "Speed: 3.9ms preprocess, 171.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 225.9ms\n",
            "Speed: 3.8ms preprocess, 225.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 232.4ms\n",
            "Speed: 4.0ms preprocess, 232.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 219.2ms\n",
            "Speed: 3.8ms preprocess, 219.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 221.2ms\n",
            "Speed: 5.2ms preprocess, 221.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 233.5ms\n",
            "Speed: 3.9ms preprocess, 233.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 231.1ms\n",
            "Speed: 4.0ms preprocess, 231.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.4ms\n",
            "Speed: 8.4ms preprocess, 223.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 230.4ms\n",
            "Speed: 6.4ms preprocess, 230.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 225.6ms\n",
            "Speed: 3.9ms preprocess, 225.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 231.4ms\n",
            "Speed: 4.0ms preprocess, 231.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 240.7ms\n",
            "Speed: 3.7ms preprocess, 240.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 228.5ms\n",
            "Speed: 5.6ms preprocess, 228.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 249.5ms\n",
            "Speed: 4.0ms preprocess, 249.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 189.4ms\n",
            "Speed: 3.8ms preprocess, 189.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 147.8ms\n",
            "Speed: 3.9ms preprocess, 147.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 146.6ms\n",
            "Speed: 5.8ms preprocess, 146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 163.9ms\n",
            "Speed: 3.9ms preprocess, 163.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 157.3ms\n",
            "Speed: 3.7ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 145.6ms\n",
            "Speed: 4.4ms preprocess, 145.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 156.4ms\n",
            "Speed: 3.8ms preprocess, 156.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 144.6ms\n",
            "Speed: 3.7ms preprocess, 144.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 162.0ms\n",
            "Speed: 3.8ms preprocess, 162.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.1ms\n",
            "Speed: 3.7ms preprocess, 144.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.6ms\n",
            "Speed: 3.8ms preprocess, 142.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.1ms\n",
            "Speed: 4.0ms preprocess, 156.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 155.6ms\n",
            "Speed: 3.6ms preprocess, 155.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 155.9ms\n",
            "Speed: 3.9ms preprocess, 155.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 140.8ms\n",
            "Speed: 4.3ms preprocess, 140.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 153.5ms\n",
            "Speed: 4.4ms preprocess, 153.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.0ms\n",
            "Speed: 4.2ms preprocess, 144.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 165.0ms\n",
            "Speed: 4.6ms preprocess, 165.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.1ms\n",
            "Speed: 3.5ms preprocess, 147.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 143.4ms\n",
            "Speed: 4.4ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 153.3ms\n",
            "Speed: 3.7ms preprocess, 153.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 152.9ms\n",
            "Speed: 5.0ms preprocess, 152.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 162.2ms\n",
            "Speed: 3.8ms preprocess, 162.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 train, 142.4ms\n",
            "Speed: 4.9ms preprocess, 142.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 train, 151.3ms\n",
            "Speed: 3.9ms preprocess, 151.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.4ms\n",
            "Speed: 4.6ms preprocess, 150.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.4ms\n",
            "Speed: 4.5ms preprocess, 146.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 167.6ms\n",
            "Speed: 3.8ms preprocess, 167.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.7ms\n",
            "Speed: 4.9ms preprocess, 145.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.9ms\n",
            "Speed: 4.2ms preprocess, 153.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 244.2ms\n",
            "Speed: 3.7ms preprocess, 244.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 157.1ms\n",
            "Speed: 8.4ms preprocess, 157.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 145.9ms\n",
            "Speed: 3.7ms preprocess, 145.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.1ms\n",
            "Speed: 4.0ms preprocess, 150.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.1ms\n",
            "Speed: 3.8ms preprocess, 154.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 157.9ms\n",
            "Speed: 4.2ms preprocess, 157.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 162.5ms\n",
            "Speed: 4.4ms preprocess, 162.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 141.7ms\n",
            "Speed: 4.7ms preprocess, 141.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 151.2ms\n",
            "Speed: 4.3ms preprocess, 151.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 153.0ms\n",
            "Speed: 4.1ms preprocess, 153.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.5ms\n",
            "Speed: 4.8ms preprocess, 146.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.1ms\n",
            "Speed: 3.7ms preprocess, 147.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.3ms\n",
            "Speed: 4.1ms preprocess, 148.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 154.3ms\n",
            "Speed: 4.7ms preprocess, 154.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.8ms\n",
            "Speed: 5.4ms preprocess, 150.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 203.1ms\n",
            "Speed: 4.0ms preprocess, 203.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 222.3ms\n",
            "Speed: 5.3ms preprocess, 222.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 227.2ms\n",
            "Speed: 4.0ms preprocess, 227.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 219.1ms\n",
            "Speed: 3.9ms preprocess, 219.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 223.6ms\n",
            "Speed: 3.7ms preprocess, 223.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 239.9ms\n",
            "Speed: 3.9ms preprocess, 239.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 236.5ms\n",
            "Speed: 3.8ms preprocess, 236.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 235.6ms\n",
            "Speed: 5.4ms preprocess, 235.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 233.8ms\n",
            "Speed: 9.8ms preprocess, 233.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 219.4ms\n",
            "Speed: 3.8ms preprocess, 219.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 230.4ms\n",
            "Speed: 4.2ms preprocess, 230.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 243.8ms\n",
            "Speed: 6.0ms preprocess, 243.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 226.3ms\n",
            "Speed: 3.9ms preprocess, 226.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 246.5ms\n",
            "Speed: 6.1ms preprocess, 246.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 217.9ms\n",
            "Speed: 3.9ms preprocess, 217.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 140.1ms\n",
            "Speed: 7.1ms preprocess, 140.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 142.2ms\n",
            "Speed: 3.5ms preprocess, 142.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 train, 159.9ms\n",
            "Speed: 4.2ms preprocess, 159.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 193.0ms\n",
            "Speed: 4.2ms preprocess, 193.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.7ms\n",
            "Speed: 3.7ms preprocess, 146.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 bird, 150.1ms\n",
            "Speed: 4.3ms preprocess, 150.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 bird, 144.2ms\n",
            "Speed: 4.6ms preprocess, 144.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.4ms\n",
            "Speed: 3.8ms preprocess, 143.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.1ms\n",
            "Speed: 4.1ms preprocess, 150.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.2ms\n",
            "Speed: 3.6ms preprocess, 146.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.5ms\n",
            "Speed: 4.3ms preprocess, 143.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.7ms\n",
            "Speed: 3.7ms preprocess, 156.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.6ms\n",
            "Speed: 4.2ms preprocess, 148.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.2ms\n",
            "Speed: 3.6ms preprocess, 148.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.1ms\n",
            "Speed: 3.5ms preprocess, 145.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 150.7ms\n",
            "Speed: 4.4ms preprocess, 150.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.1ms\n",
            "Speed: 3.6ms preprocess, 158.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.3ms\n",
            "Speed: 3.9ms preprocess, 156.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.7ms\n",
            "Speed: 3.6ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.3ms\n",
            "Speed: 8.3ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.0ms\n",
            "Speed: 5.5ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.3ms\n",
            "Speed: 3.7ms preprocess, 147.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.3ms\n",
            "Speed: 3.5ms preprocess, 152.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.1ms\n",
            "Speed: 3.8ms preprocess, 143.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.7ms\n",
            "Speed: 3.6ms preprocess, 152.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 160.6ms\n",
            "Speed: 3.9ms preprocess, 160.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 156.9ms\n",
            "Speed: 4.6ms preprocess, 156.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.3ms\n",
            "Speed: 3.7ms preprocess, 149.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 144.4ms\n",
            "Speed: 5.0ms preprocess, 144.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 145.1ms\n",
            "Speed: 4.8ms preprocess, 145.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.5ms\n",
            "Speed: 5.2ms preprocess, 149.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.8ms\n",
            "Speed: 4.2ms preprocess, 148.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.7ms\n",
            "Speed: 4.0ms preprocess, 148.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 151.1ms\n",
            "Speed: 4.4ms preprocess, 151.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 146.5ms\n",
            "Speed: 4.2ms preprocess, 146.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.5ms\n",
            "Speed: 10.5ms preprocess, 154.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 155.9ms\n",
            "Speed: 4.7ms preprocess, 155.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.0ms\n",
            "Speed: 4.6ms preprocess, 148.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.5ms\n",
            "Speed: 4.4ms preprocess, 158.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 165.1ms\n",
            "Speed: 4.0ms preprocess, 165.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 152.5ms\n",
            "Speed: 4.0ms preprocess, 152.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.9ms\n",
            "Speed: 4.1ms preprocess, 142.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.4ms\n",
            "Speed: 7.1ms preprocess, 148.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 148.8ms\n",
            "Speed: 5.3ms preprocess, 148.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 233.5ms\n",
            "Speed: 5.8ms preprocess, 233.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 218.8ms\n",
            "Speed: 6.4ms preprocess, 218.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 222.1ms\n",
            "Speed: 4.6ms preprocess, 222.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 251.6ms\n",
            "Speed: 3.8ms preprocess, 251.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 224.2ms\n",
            "Speed: 6.0ms preprocess, 224.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 229.5ms\n",
            "Speed: 5.7ms preprocess, 229.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 231.7ms\n",
            "Speed: 6.3ms preprocess, 231.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 232.6ms\n",
            "Speed: 4.3ms preprocess, 232.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 223.4ms\n",
            "Speed: 4.0ms preprocess, 223.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 224.1ms\n",
            "Speed: 5.9ms preprocess, 224.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 260.0ms\n",
            "Speed: 3.8ms preprocess, 260.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 234.7ms\n",
            "Speed: 3.8ms preprocess, 234.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 229.0ms\n",
            "Speed: 4.1ms preprocess, 229.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 200.8ms\n",
            "Speed: 4.1ms preprocess, 200.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 147.4ms\n",
            "Speed: 3.9ms preprocess, 147.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.8ms\n",
            "Speed: 4.5ms preprocess, 151.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 167.9ms\n",
            "Speed: 4.2ms preprocess, 167.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.4ms\n",
            "Speed: 4.2ms preprocess, 142.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 142.9ms\n",
            "Speed: 8.6ms preprocess, 142.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.2ms\n",
            "Speed: 3.7ms preprocess, 143.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 150.3ms\n",
            "Speed: 3.9ms preprocess, 150.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.3ms\n",
            "Speed: 3.8ms preprocess, 154.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.9ms\n",
            "Speed: 3.6ms preprocess, 143.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.7ms\n",
            "Speed: 4.2ms preprocess, 153.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.3ms\n",
            "Speed: 4.1ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 163.7ms\n",
            "Speed: 3.9ms preprocess, 163.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 150.0ms\n",
            "Speed: 4.3ms preprocess, 150.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 145.2ms\n",
            "Speed: 4.2ms preprocess, 145.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 161.0ms\n",
            "Speed: 3.8ms preprocess, 161.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 151.3ms\n",
            "Speed: 3.7ms preprocess, 151.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 181.5ms\n",
            "Speed: 3.8ms preprocess, 181.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.5ms\n",
            "Speed: 3.8ms preprocess, 154.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.5ms\n",
            "Speed: 5.3ms preprocess, 156.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 154.7ms\n",
            "Speed: 3.7ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 159.2ms\n",
            "Speed: 3.7ms preprocess, 159.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.8ms\n",
            "Speed: 3.8ms preprocess, 147.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 163.2ms\n",
            "Speed: 5.7ms preprocess, 163.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 152.3ms\n",
            "Speed: 4.0ms preprocess, 152.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.1ms\n",
            "Speed: 4.6ms preprocess, 146.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 154.0ms\n",
            "Speed: 4.1ms preprocess, 154.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 148.1ms\n",
            "Speed: 4.0ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.8ms\n",
            "Speed: 4.3ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 150.0ms\n",
            "Speed: 5.0ms preprocess, 150.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 164.2ms\n",
            "Speed: 4.4ms preprocess, 164.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.5ms\n",
            "Speed: 4.1ms preprocess, 146.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 158.7ms\n",
            "Speed: 4.3ms preprocess, 158.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.9ms\n",
            "Speed: 4.6ms preprocess, 149.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 143.1ms\n",
            "Speed: 4.1ms preprocess, 143.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.4ms\n",
            "Speed: 4.0ms preprocess, 148.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 sheep, 152.5ms\n",
            "Speed: 3.7ms preprocess, 152.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.8ms\n",
            "Speed: 3.8ms preprocess, 149.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.6ms\n",
            "Speed: 3.9ms preprocess, 145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 161.7ms\n",
            "Speed: 3.6ms preprocess, 161.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 4.0ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.3ms\n",
            "Speed: 3.7ms preprocess, 153.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 149.0ms\n",
            "Speed: 4.0ms preprocess, 149.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 144.6ms\n",
            "Speed: 3.6ms preprocess, 144.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 236.8ms\n",
            "Speed: 3.8ms preprocess, 236.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 224.6ms\n",
            "Speed: 4.8ms preprocess, 224.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 216.5ms\n",
            "Speed: 3.9ms preprocess, 216.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 222.5ms\n",
            "Speed: 3.8ms preprocess, 222.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 217.7ms\n",
            "Speed: 7.6ms preprocess, 217.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 232.1ms\n",
            "Speed: 3.9ms preprocess, 232.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 230.2ms\n",
            "Speed: 6.7ms preprocess, 230.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 231.4ms\n",
            "Speed: 3.9ms preprocess, 231.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 230.1ms\n",
            "Speed: 6.0ms preprocess, 230.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 240.4ms\n",
            "Speed: 7.1ms preprocess, 240.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 227.0ms\n",
            "Speed: 3.9ms preprocess, 227.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 217.9ms\n",
            "Speed: 6.6ms preprocess, 217.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 240.1ms\n",
            "Speed: 3.9ms preprocess, 240.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 fire hydrant, 233.4ms\n",
            "Speed: 3.8ms preprocess, 233.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.1ms\n",
            "Speed: 4.4ms preprocess, 149.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.0ms\n",
            "Speed: 3.6ms preprocess, 145.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 159.2ms\n",
            "Speed: 3.7ms preprocess, 159.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 157.4ms\n",
            "Speed: 3.7ms preprocess, 157.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 143.5ms\n",
            "Speed: 4.4ms preprocess, 143.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.9ms\n",
            "Speed: 3.9ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.9ms\n",
            "Speed: 5.8ms preprocess, 145.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 172.2ms\n",
            "Speed: 3.6ms preprocess, 172.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 148.7ms\n",
            "Speed: 4.2ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 142.9ms\n",
            "Speed: 7.4ms preprocess, 142.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.3ms\n",
            "Speed: 3.8ms preprocess, 149.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 163.3ms\n",
            "Speed: 4.8ms preprocess, 163.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 146.1ms\n",
            "Speed: 5.4ms preprocess, 146.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 151.5ms\n",
            "Speed: 4.7ms preprocess, 151.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.6ms\n",
            "Speed: 4.6ms preprocess, 143.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 152.0ms\n",
            "Speed: 3.9ms preprocess, 152.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 149.8ms\n",
            "Speed: 4.4ms preprocess, 149.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 144.8ms\n",
            "Speed: 3.9ms preprocess, 144.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.0ms\n",
            "Speed: 3.8ms preprocess, 146.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 157.8ms\n",
            "Speed: 4.1ms preprocess, 157.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 170.8ms\n",
            "Speed: 6.3ms preprocess, 170.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 149.2ms\n",
            "Speed: 4.9ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.6ms\n",
            "Speed: 4.3ms preprocess, 146.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.2ms\n",
            "Speed: 4.2ms preprocess, 147.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 150.1ms\n",
            "Speed: 4.9ms preprocess, 150.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 154.3ms\n",
            "Speed: 4.8ms preprocess, 154.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.0ms\n",
            "Speed: 4.7ms preprocess, 142.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 149.6ms\n",
            "Speed: 4.0ms preprocess, 149.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 151.7ms\n",
            "Speed: 3.7ms preprocess, 151.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 160.0ms\n",
            "Speed: 3.7ms preprocess, 160.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 145.7ms\n",
            "Speed: 4.7ms preprocess, 145.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 150.2ms\n",
            "Speed: 5.5ms preprocess, 150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 146.1ms\n",
            "Speed: 5.7ms preprocess, 146.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 148.3ms\n",
            "Speed: 6.0ms preprocess, 148.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 149.6ms\n",
            "Speed: 3.9ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 149.1ms\n",
            "Speed: 4.0ms preprocess, 149.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 141.0ms\n",
            "Speed: 4.7ms preprocess, 141.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 151.2ms\n",
            "Speed: 3.8ms preprocess, 151.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 163.6ms\n",
            "Speed: 3.8ms preprocess, 163.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 151.6ms\n",
            "Speed: 3.8ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.5ms\n",
            "Speed: 3.8ms preprocess, 147.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 160.4ms\n",
            "Speed: 4.7ms preprocess, 160.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 147.4ms\n",
            "Speed: 4.5ms preprocess, 147.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 221.4ms\n",
            "Speed: 4.6ms preprocess, 221.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 232.7ms\n",
            "Speed: 3.8ms preprocess, 232.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 224.4ms\n",
            "Speed: 6.0ms preprocess, 224.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 224.2ms\n",
            "Speed: 6.4ms preprocess, 224.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 228.3ms\n",
            "Speed: 3.8ms preprocess, 228.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 228.4ms\n",
            "Speed: 6.8ms preprocess, 228.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 228.8ms\n",
            "Speed: 5.3ms preprocess, 228.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 229.2ms\n",
            "Speed: 6.4ms preprocess, 229.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 219.5ms\n",
            "Speed: 5.7ms preprocess, 219.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 234.1ms\n",
            "Speed: 3.6ms preprocess, 234.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 245.6ms\n",
            "Speed: 4.2ms preprocess, 245.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 235.6ms\n",
            "Speed: 6.1ms preprocess, 235.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 240.2ms\n",
            "Speed: 4.1ms preprocess, 240.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 158.9ms\n",
            "Speed: 7.4ms preprocess, 158.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 143.4ms\n",
            "Speed: 4.5ms preprocess, 143.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 151.9ms\n",
            "Speed: 3.7ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 161.2ms\n",
            "Speed: 4.2ms preprocess, 161.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 154.0ms\n",
            "Speed: 3.6ms preprocess, 154.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 144.5ms\n",
            "Speed: 3.7ms preprocess, 144.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 154.9ms\n",
            "Speed: 3.6ms preprocess, 154.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 165.2ms\n",
            "Speed: 3.8ms preprocess, 165.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 145.1ms\n",
            "Speed: 3.7ms preprocess, 145.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 143.8ms\n",
            "Speed: 3.7ms preprocess, 143.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 141.2ms\n",
            "Speed: 4.6ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.7ms\n",
            "Speed: 4.2ms preprocess, 144.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 166.2ms\n",
            "Speed: 4.0ms preprocess, 166.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 144.9ms\n",
            "Speed: 3.8ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.5ms\n",
            "Speed: 3.7ms preprocess, 148.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 147.1ms\n",
            "Speed: 3.6ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.6ms\n",
            "Speed: 3.6ms preprocess, 156.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 bird, 146.9ms\n",
            "Speed: 4.7ms preprocess, 146.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 152.3ms\n",
            "Speed: 3.6ms preprocess, 152.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 172.7ms\n",
            "Speed: 4.3ms preprocess, 172.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 157.4ms\n",
            "Speed: 4.5ms preprocess, 157.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 159.7ms\n",
            "Speed: 4.2ms preprocess, 159.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 148.1ms\n",
            "Speed: 3.6ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 149.9ms\n",
            "Speed: 4.4ms preprocess, 149.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bench, 150.9ms\n",
            "Speed: 4.5ms preprocess, 150.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 160.7ms\n",
            "Speed: 4.5ms preprocess, 160.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 146.1ms\n",
            "Speed: 4.1ms preprocess, 146.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 147.4ms\n",
            "Speed: 4.9ms preprocess, 147.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 144.5ms\n",
            "Speed: 6.3ms preprocess, 144.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.7ms\n",
            "Speed: 3.6ms preprocess, 150.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 147.2ms\n",
            "Speed: 4.1ms preprocess, 147.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 162.5ms\n",
            "Speed: 4.3ms preprocess, 162.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 152.5ms\n",
            "Speed: 4.0ms preprocess, 152.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 152.7ms\n",
            "Speed: 4.3ms preprocess, 152.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.9ms\n",
            "Speed: 3.5ms preprocess, 148.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.0ms\n",
            "Speed: 4.5ms preprocess, 148.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 158.0ms\n",
            "Speed: 3.7ms preprocess, 158.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.7ms\n",
            "Speed: 3.6ms preprocess, 149.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.9ms\n",
            "Speed: 4.1ms preprocess, 150.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 143.6ms\n",
            "Speed: 3.9ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.5ms\n",
            "Speed: 3.9ms preprocess, 149.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 142.9ms\n",
            "Speed: 4.8ms preprocess, 142.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.1ms\n",
            "Speed: 3.8ms preprocess, 150.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 246.6ms\n",
            "Speed: 4.3ms preprocess, 246.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.5ms\n",
            "Speed: 3.9ms preprocess, 149.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 148.9ms\n",
            "Speed: 4.4ms preprocess, 148.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 154.9ms\n",
            "Speed: 4.2ms preprocess, 154.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 245.2ms\n",
            "Speed: 7.8ms preprocess, 245.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 227.5ms\n",
            "Speed: 3.8ms preprocess, 227.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 230.2ms\n",
            "Speed: 3.8ms preprocess, 230.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 221.9ms\n",
            "Speed: 3.7ms preprocess, 221.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 229.7ms\n",
            "Speed: 3.7ms preprocess, 229.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 239.1ms\n",
            "Speed: 3.8ms preprocess, 239.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 225.5ms\n",
            "Speed: 3.8ms preprocess, 225.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 251.7ms\n",
            "Speed: 3.7ms preprocess, 251.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 229.6ms\n",
            "Speed: 3.7ms preprocess, 229.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 222.6ms\n",
            "Speed: 3.8ms preprocess, 222.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 217.2ms\n",
            "Speed: 3.9ms preprocess, 217.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 222.1ms\n",
            "Speed: 3.7ms preprocess, 222.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 228.8ms\n",
            "Speed: 3.8ms preprocess, 228.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 239.5ms\n",
            "Speed: 3.6ms preprocess, 239.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.solutions import object_counter\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Computer Vision/startic 3lvx enhanced.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define region points\n",
        "region_points = [(20, 400), (1080, 404), (1080, 360), (20, 360)]\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"object_counting_output.avi\",\n",
        "                       cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                       fps,\n",
        "                       (w, h))\n",
        "\n",
        "# Init Object Counter\n",
        "counter = object_counter.ObjectCounter()\n",
        "counter.set_args(view_img=True,\n",
        "                 reg_pts=region_points,\n",
        "                 classes_names=model.names,\n",
        "                 draw_tracks=True,\n",
        "                 line_thickness=2)\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "    tracks = model.track(im0, persist=True, show=False)\n",
        "\n",
        "    im0 = counter.start_counting(im0, tracks)\n",
        "    video_writer.write(im0)\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}